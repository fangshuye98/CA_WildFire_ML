{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Force garbage collection\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_recall_curve,auc\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas version\n",
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "# check python version and all packages version\n",
    "def check_python_version():\n",
    "    import sys\n",
    "    print(\"Python version\")\n",
    "    print (sys.version)\n",
    "    print(\"Pandas version\")\n",
    "    print(pd.__version__)\n",
    "\n",
    "check_python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_features = ['dead_fuel_moisture_1000hr',\n",
    "       'dead_fuel_moisture_100hr', \n",
    "       'max_air_temperature', 'max_relative_humidity', \n",
    "       'min_air_temperature', 'min_relative_humidity', 'precipitation_amount',\n",
    "       'specific_humidity', 'surface_downwelling_shortwave_flux_in_air',\n",
    "       #'wind_from_direction', \n",
    "       'wind_speed', 'wind_direction_category', 'SWE',\n",
    "       'population_density',\n",
    "       'LAI', \n",
    "       #'pdsi', \n",
    "       #'IS_FIRE', \n",
    "       #'min_FIRE_SIZE', 'max_FIRE_SIZE', 'Year','fire_attribute', \n",
    "       'veg', \n",
    "       #'slope_avg', \n",
    "       'slope_max',\n",
    "       'road_density_km_km2',\n",
    "       'line_density_km_per_cell' \n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, features, label_col):\n",
    "    X_train = train_data[features]\n",
    "    y_train = train_data[label_col]\n",
    "    # train the model\n",
    "    model = xgb.XGBClassifier(eval_metric='logloss', tree_method='hist')\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# define function to calculate precision and recall based on a threshold\n",
    "def calculate_precision_recall(y_true, y_pred_proba, threshold, print_output=False):\n",
    "    y_pred = (y_pred_proba > threshold).astype(int)\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "    precision = confusion[1, 1] / (confusion[1, 1] + confusion[0, 1])\n",
    "    recall = confusion[1, 1] / (confusion[1, 1] + confusion[1, 0])\n",
    "    # F1 score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    if print_output:\n",
    "        print(f'Threshold: {threshold:.2f}')\n",
    "        print(f'Precision: {precision * 100:.2f}%')\n",
    "        print(f'Recall: {recall * 100:.2f}%')\n",
    "        print(\"Confusion Matrix\")\n",
    "        print(pd.DataFrame(confusion, index=['True Neg', 'True Pos'], columns=['Pred Neg', 'Pred Pos']))\n",
    "    # get TP, TN, FP, FN\n",
    "    TP = confusion[1, 1]\n",
    "    TN = confusion[0, 0]\n",
    "    FP = confusion[0, 1]\n",
    "    FN = confusion[1, 0]\n",
    "    return TP, TN, FP, FN, precision, recall, f1\n",
    "\n",
    "def evaluate_model(model, test_data, features, label_col):\n",
    "    X_test = test_data[features]\n",
    "    y_test = test_data[label_col]\n",
    "    # predict the probability of fire\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    # calculate the roc_auc_score\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    # print roc_auc in a sentence\n",
    "    # print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "    # Calculate precision and recall values\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "    # Calculate the area under the precision-recall curve\n",
    "    auc_pr = auc(recall, precision)\n",
    "    # print(f\"Area Under Precision-Recall Curve (AUC-PR): {auc_pr:.2f}\")\n",
    "    # calculate precision and recall at thresholds 0.5\n",
    "    TP, TN, FP, FN, precision5, recall5, f15 = calculate_precision_recall(y_test, y_pred, 0.5)\n",
    "    return roc_auc, auc_pr, TP, TN, FP, FN, precision5, recall5, f15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Water Years 2007 using training data: 2000-10-01 00:00:00 ~ 2006-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "def get_water_year_range(target_year, num_years=6):\n",
    "    min_year = target_year - num_years - 1\n",
    "    min_day = f\"{min_year}-10-01 00:00:00\"\n",
    "    max_day = f\"{target_year-1}-09-30 00:00:00\"\n",
    "    return min_day, max_day\n",
    "\n",
    "# Example: Get range for Water Year 2007\n",
    "target_year = 2007\n",
    "min_day, max_day = get_water_year_range(target_year)\n",
    "\n",
    "print(f\"Predict Water Years {target_year} using training data: {min_day} ~ {max_day}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing years: 100%|██████████| 20/20 [08:23<00:00, 25.19s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "log_messages = []\n",
    "log_messages.append(\"Model using extended years and features with powerline density\")\n",
    "# add log to record the current time\n",
    "log_messages.append(f\"Start time: {pd.Timestamp.now()}\")\n",
    "# Define the range of years to predict\n",
    "years = range(2001, 2021)\n",
    "\n",
    "\n",
    "# Plot\n",
    "model_path = '../../Model/Extended_Data_Water_Year'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "save_predictions_path = '../../Clean_Data/Model_Data/Evaluation/Features_w_Label_w_pred/Extended_Data_Water_Year/parquet'\n",
    "if not os.path.exists(save_predictions_path):\n",
    "    os.makedirs(save_predictions_path)  \n",
    "\n",
    "# surpass the warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "mod_Human = pd.read_parquet(f'../../Clean_Data/Model_Data/Downsample/Features_w_Label/features_w_label_downsample_1994_2020.parquet')\n",
    "\n",
    "input_path = '../../Clean_Data/Model_Data/Evaluation/Features_w_Label/Extended_Data_Water_Year'\n",
    "# Iterate over the years with a progress bar\n",
    "for year in tqdm(years, desc=\"Processing years\"):\n",
    "    log_messages.append(\"-\" * 50)\n",
    "    # log current water year\n",
    "    log_messages.append(f\"Processing Water Year: {year}\")\n",
    "    # read eval data, prev-year Oct - current year Sep\n",
    "    Eval_Human = pd.read_parquet(f'{input_path}/{year}_features_w_label.parquet')\n",
    "\n",
    "    # get water year range\n",
    "    min_day, max_day = get_water_year_range(year)\n",
    "    # filter the training data\n",
    "    train_data = mod_Human[(mod_Human['day'] >= min_day) & (mod_Human['day'] <= max_day)]\n",
    "    # use log message to show the min and max of day from mod_Human\n",
    "    log_messages.append(f\"Training Data Day min: {train_data['day'].min()}, max: {train_data['day'].max()}\")\n",
    "    #mod_Human = mod_Human[features_to_keep]\n",
    "    #Eval_Human = Eval_Human[features_to_keep]\n",
    "\n",
    "    cat_columns = ['wind_direction_category','veg']\n",
    "\n",
    "    # one hot encoding\n",
    "    train_data = pd.get_dummies(train_data, columns=cat_columns)\n",
    "    Eval_Human = pd.get_dummies(Eval_Human, columns=cat_columns)\n",
    "\n",
    "    # extract column names starting with 'wind_direction_category_' and 'veg_'\n",
    "    wind_direction_category_cols = [col for col in train_data.columns if col.startswith('wind_direction_category_')]\n",
    "    veg_cols = [col for col in train_data.columns if col.startswith('veg_') and col != 'veg_type_details']\n",
    "\n",
    "    features = initial_features + wind_direction_category_cols + veg_cols\n",
    "    # drop cat_columns from features\n",
    "    features = [col for col in features if col not in cat_columns]\n",
    "\n",
    "    label_col = 'IS_FIRE'\n",
    "    model = train_model(train_data, features, label_col)\n",
    "    # save model to a pickle file\n",
    "    with open(f'{model_path}/predict_{year}_6yr_model.pkl', 'wb') as f:\n",
    "         pickle.dump(model, f)\n",
    "    # save model to ../../Model/predict_year\n",
    "    # model.save_model(f'../../Model/predict_{year}_6yr_model.json')\n",
    "    # evaluate the model\n",
    "    roc_auc, auc_pr, TP, TN, FP, FN, precision5, recall5, f15 = evaluate_model(model, Eval_Human, features, label_col)\n",
    "    # append the results to the list\n",
    "    results.append([year, roc_auc, auc_pr, TP, TN, FP, FN, precision5, recall5, f15])\n",
    "\n",
    "    # add predictions to Eval_Human\n",
    "    Eval_Human['predictions'] = model.predict_proba(Eval_Human[features])[:, 1]\n",
    "    # save the predictions to a parquet file\n",
    "    Eval_Human.to_parquet(f'{save_predictions_path}/{year}_predictions.parquet', index=False)\n",
    "\n",
    "    # clean up the dataframes\n",
    "    del train_data\n",
    "    del Eval_Human\n",
    "\n",
    "    # clean the cache\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the log messages to a log file\n",
    "with open('../../Logs/Clean_Extended_Data/model_training_6_years.txt', 'w') as log_file:\n",
    "    log_file.write('\\n'.join(log_messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign column names to the results\n",
    "results_pd = pd.DataFrame(results, columns=['Year', 'ROC_AUC', 'AUC_PR', 'TP', 'TN', 'FP', 'FN', 'Precision_0.5', 'Recall_0.5', 'F1_0.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>AUC_PR</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Precision_0.5</th>\n",
       "      <th>Recall_0.5</th>\n",
       "      <th>F1_0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.872694</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>121</td>\n",
       "      <td>4728417</td>\n",
       "      <td>1422</td>\n",
       "      <td>3653</td>\n",
       "      <td>0.078419</td>\n",
       "      <td>0.032061</td>\n",
       "      <td>0.045514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>0.870402</td>\n",
       "      <td>0.032035</td>\n",
       "      <td>129</td>\n",
       "      <td>4730437</td>\n",
       "      <td>732</td>\n",
       "      <td>3593</td>\n",
       "      <td>0.149826</td>\n",
       "      <td>0.034659</td>\n",
       "      <td>0.056295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>0.874875</td>\n",
       "      <td>0.024048</td>\n",
       "      <td>98</td>\n",
       "      <td>4733581</td>\n",
       "      <td>499</td>\n",
       "      <td>3246</td>\n",
       "      <td>0.164154</td>\n",
       "      <td>0.029306</td>\n",
       "      <td>0.049734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>0.869826</td>\n",
       "      <td>0.021229</td>\n",
       "      <td>90</td>\n",
       "      <td>4744289</td>\n",
       "      <td>539</td>\n",
       "      <td>3652</td>\n",
       "      <td>0.143084</td>\n",
       "      <td>0.024051</td>\n",
       "      <td>0.041181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>0.882640</td>\n",
       "      <td>0.023210</td>\n",
       "      <td>65</td>\n",
       "      <td>4728227</td>\n",
       "      <td>273</td>\n",
       "      <td>3319</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.019208</td>\n",
       "      <td>0.034927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2006</td>\n",
       "      <td>0.887353</td>\n",
       "      <td>0.028742</td>\n",
       "      <td>128</td>\n",
       "      <td>4719640</td>\n",
       "      <td>385</td>\n",
       "      <td>4083</td>\n",
       "      <td>0.249513</td>\n",
       "      <td>0.030397</td>\n",
       "      <td>0.054191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007</td>\n",
       "      <td>0.878800</td>\n",
       "      <td>0.032650</td>\n",
       "      <td>139</td>\n",
       "      <td>4687567</td>\n",
       "      <td>458</td>\n",
       "      <td>5043</td>\n",
       "      <td>0.232831</td>\n",
       "      <td>0.026824</td>\n",
       "      <td>0.048105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008</td>\n",
       "      <td>0.873984</td>\n",
       "      <td>0.026308</td>\n",
       "      <td>134</td>\n",
       "      <td>4697293</td>\n",
       "      <td>736</td>\n",
       "      <td>4382</td>\n",
       "      <td>0.154023</td>\n",
       "      <td>0.029672</td>\n",
       "      <td>0.049759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.882543</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>136</td>\n",
       "      <td>4705515</td>\n",
       "      <td>911</td>\n",
       "      <td>3286</td>\n",
       "      <td>0.129895</td>\n",
       "      <td>0.039743</td>\n",
       "      <td>0.060864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010</td>\n",
       "      <td>0.892175</td>\n",
       "      <td>0.013851</td>\n",
       "      <td>65</td>\n",
       "      <td>4717214</td>\n",
       "      <td>678</td>\n",
       "      <td>2840</td>\n",
       "      <td>0.087483</td>\n",
       "      <td>0.022375</td>\n",
       "      <td>0.035636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2011</td>\n",
       "      <td>0.898152</td>\n",
       "      <td>0.032825</td>\n",
       "      <td>107</td>\n",
       "      <td>4712687</td>\n",
       "      <td>511</td>\n",
       "      <td>2638</td>\n",
       "      <td>0.173139</td>\n",
       "      <td>0.038980</td>\n",
       "      <td>0.063634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012</td>\n",
       "      <td>0.853988</td>\n",
       "      <td>0.017178</td>\n",
       "      <td>107</td>\n",
       "      <td>4706132</td>\n",
       "      <td>1574</td>\n",
       "      <td>2993</td>\n",
       "      <td>0.063653</td>\n",
       "      <td>0.034516</td>\n",
       "      <td>0.044761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013</td>\n",
       "      <td>0.868167</td>\n",
       "      <td>0.026761</td>\n",
       "      <td>128</td>\n",
       "      <td>4716540</td>\n",
       "      <td>1002</td>\n",
       "      <td>2695</td>\n",
       "      <td>0.113274</td>\n",
       "      <td>0.045342</td>\n",
       "      <td>0.064761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014</td>\n",
       "      <td>0.847461</td>\n",
       "      <td>0.021920</td>\n",
       "      <td>101</td>\n",
       "      <td>4732561</td>\n",
       "      <td>815</td>\n",
       "      <td>2896</td>\n",
       "      <td>0.110262</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.051623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015</td>\n",
       "      <td>0.859677</td>\n",
       "      <td>0.020648</td>\n",
       "      <td>91</td>\n",
       "      <td>4735657</td>\n",
       "      <td>436</td>\n",
       "      <td>2439</td>\n",
       "      <td>0.172676</td>\n",
       "      <td>0.035968</td>\n",
       "      <td>0.059535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.872547</td>\n",
       "      <td>0.036103</td>\n",
       "      <td>119</td>\n",
       "      <td>4745276</td>\n",
       "      <td>351</td>\n",
       "      <td>2670</td>\n",
       "      <td>0.253191</td>\n",
       "      <td>0.042668</td>\n",
       "      <td>0.073029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.891640</td>\n",
       "      <td>0.014942</td>\n",
       "      <td>60</td>\n",
       "      <td>4733227</td>\n",
       "      <td>435</td>\n",
       "      <td>2629</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.022313</td>\n",
       "      <td>0.037688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.867255</td>\n",
       "      <td>0.016590</td>\n",
       "      <td>64</td>\n",
       "      <td>4729979</td>\n",
       "      <td>345</td>\n",
       "      <td>2905</td>\n",
       "      <td>0.156479</td>\n",
       "      <td>0.021556</td>\n",
       "      <td>0.037892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.869305</td>\n",
       "      <td>0.007877</td>\n",
       "      <td>34</td>\n",
       "      <td>4732324</td>\n",
       "      <td>329</td>\n",
       "      <td>1878</td>\n",
       "      <td>0.093664</td>\n",
       "      <td>0.017782</td>\n",
       "      <td>0.029890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.873855</td>\n",
       "      <td>0.010622</td>\n",
       "      <td>40</td>\n",
       "      <td>4729930</td>\n",
       "      <td>354</td>\n",
       "      <td>2298</td>\n",
       "      <td>0.101523</td>\n",
       "      <td>0.017109</td>\n",
       "      <td>0.029283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year   ROC_AUC    AUC_PR   TP       TN    FP    FN  Precision_0.5  \\\n",
       "0   2001  0.872694  0.015152  121  4728417  1422  3653       0.078419   \n",
       "1   2002  0.870402  0.032035  129  4730437   732  3593       0.149826   \n",
       "2   2003  0.874875  0.024048   98  4733581   499  3246       0.164154   \n",
       "3   2004  0.869826  0.021229   90  4744289   539  3652       0.143084   \n",
       "4   2005  0.882640  0.023210   65  4728227   273  3319       0.192308   \n",
       "5   2006  0.887353  0.028742  128  4719640   385  4083       0.249513   \n",
       "6   2007  0.878800  0.032650  139  4687567   458  5043       0.232831   \n",
       "7   2008  0.873984  0.026308  134  4697293   736  4382       0.154023   \n",
       "8   2009  0.882543  0.023328  136  4705515   911  3286       0.129895   \n",
       "9   2010  0.892175  0.013851   65  4717214   678  2840       0.087483   \n",
       "10  2011  0.898152  0.032825  107  4712687   511  2638       0.173139   \n",
       "11  2012  0.853988  0.017178  107  4706132  1574  2993       0.063653   \n",
       "12  2013  0.868167  0.026761  128  4716540  1002  2695       0.113274   \n",
       "13  2014  0.847461  0.021920  101  4732561   815  2896       0.110262   \n",
       "14  2015  0.859677  0.020648   91  4735657   436  2439       0.172676   \n",
       "15  2016  0.872547  0.036103  119  4745276   351  2670       0.253191   \n",
       "16  2017  0.891640  0.014942   60  4733227   435  2629       0.121212   \n",
       "17  2018  0.867255  0.016590   64  4729979   345  2905       0.156479   \n",
       "18  2019  0.869305  0.007877   34  4732324   329  1878       0.093664   \n",
       "19  2020  0.873855  0.010622   40  4729930   354  2298       0.101523   \n",
       "\n",
       "    Recall_0.5    F1_0.5  \n",
       "0     0.032061  0.045514  \n",
       "1     0.034659  0.056295  \n",
       "2     0.029306  0.049734  \n",
       "3     0.024051  0.041181  \n",
       "4     0.019208  0.034927  \n",
       "5     0.030397  0.054191  \n",
       "6     0.026824  0.048105  \n",
       "7     0.029672  0.049759  \n",
       "8     0.039743  0.060864  \n",
       "9     0.022375  0.035636  \n",
       "10    0.038980  0.063634  \n",
       "11    0.034516  0.044761  \n",
       "12    0.045342  0.064761  \n",
       "13    0.033700  0.051623  \n",
       "14    0.035968  0.059535  \n",
       "15    0.042668  0.073029  \n",
       "16    0.022313  0.037688  \n",
       "17    0.021556  0.037892  \n",
       "18    0.017782  0.029890  \n",
       "19    0.017109  0.029283  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del all variables to free up memory\n",
    "del mod_Human\n",
    "del results\n",
    "del results_pd\n",
    "# clean the cache\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all data\n",
    "for name in dir():\n",
    "    if not name.startswith('_'):\n",
    "        del globals()[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing years: 100%|██████████| 20/20 [55:13<00:00, 165.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# save all parquet to csv\n",
    "years = range(2001, 2021)\n",
    "\n",
    "input_path = '../../Clean_Data/Model_Data/Evaluation/Features_w_Label_w_pred/Extended_Data_Water_Year/parquet'\n",
    "output_path = '../../Clean_Data/Model_Data/Evaluation/Features_w_Label_w_pred/Extended_Data_Water_Year/csv'\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "for year in tqdm(years, desc=\"Processing years\"):\n",
    "    # read the parquet file\n",
    "    df = pd.read_parquet(f'{input_path}/{year}_predictions.parquet')  \n",
    "    # write to csv\n",
    "    df.to_csv(f'{output_path}/{year}_predictions.csv', index=False)\n",
    "\n",
    "    # clean up the dataframes\n",
    "    del df\n",
    "    # clean the cache\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
