{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Force garbage collection\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_recall_curve,auc\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas version\n",
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "# check python version and all packages version\n",
    "def check_python_version():\n",
    "    import sys\n",
    "    print(\"Python version\")\n",
    "    print (sys.version)\n",
    "    print(\"Pandas version\")\n",
    "    print(pd.__version__)\n",
    "\n",
    "check_python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_features = ['dead_fuel_moisture_1000hr',\n",
    "       'dead_fuel_moisture_100hr', \n",
    "       'max_air_temperature', 'max_relative_humidity', \n",
    "       'min_air_temperature', 'min_relative_humidity', 'precipitation_amount',\n",
    "       'specific_humidity', 'surface_downwelling_shortwave_flux_in_air',\n",
    "       #'wind_from_direction', \n",
    "       'wind_speed', 'wind_direction_category', 'SWE',\n",
    "       'population_density',\n",
    "       'LAI', \n",
    "       #'pdsi', \n",
    "       #'IS_FIRE', \n",
    "       #'min_FIRE_SIZE', 'max_FIRE_SIZE', 'Year','fire_attribute', \n",
    "       'veg', \n",
    "       #'slope_avg', \n",
    "       'slope_max',\n",
    "       'road_density_km_km2',\n",
    "       'line_density_km_per_cell' \n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, features, label_col):\n",
    "    X_train = train_data[features]\n",
    "    y_train = train_data[label_col]\n",
    "    # train the model\n",
    "    model = xgb.XGBClassifier(eval_metric='logloss', tree_method='hist')\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# define function to calculate precision and recall based on a threshold\n",
    "def calculate_precision_recall(y_true, y_pred_proba, threshold, print_output=False):\n",
    "    y_pred = (y_pred_proba > threshold).astype(int)\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "    precision = confusion[1, 1] / (confusion[1, 1] + confusion[0, 1])\n",
    "    recall = confusion[1, 1] / (confusion[1, 1] + confusion[1, 0])\n",
    "    # F1 score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    if print_output:\n",
    "        print(f'Threshold: {threshold:.2f}')\n",
    "        print(f'Precision: {precision * 100:.2f}%')\n",
    "        print(f'Recall: {recall * 100:.2f}%')\n",
    "        print(\"Confusion Matrix\")\n",
    "        print(pd.DataFrame(confusion, index=['True Neg', 'True Pos'], columns=['Pred Neg', 'Pred Pos']))\n",
    "    # get TP, TN, FP, FN\n",
    "    TP = confusion[1, 1]\n",
    "    TN = confusion[0, 0]\n",
    "    FP = confusion[0, 1]\n",
    "    FN = confusion[1, 0]\n",
    "    return TP, TN, FP, FN, precision, recall, f1\n",
    "\n",
    "def evaluate_model(model, test_data, features, label_col):\n",
    "    X_test = test_data[features]\n",
    "    y_test = test_data[label_col]\n",
    "    # predict the probability of fire\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    # calculate the roc_auc_score\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    # print roc_auc in a sentence\n",
    "    # print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "    # Calculate precision and recall values\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "    # Calculate the area under the precision-recall curve\n",
    "    auc_pr = auc(recall, precision)\n",
    "    # print(f\"Area Under Precision-Recall Curve (AUC-PR): {auc_pr:.2f}\")\n",
    "    # calculate precision and recall at thresholds 0.5\n",
    "    TP, TN, FP, FN, precision5, recall5, f15 = calculate_precision_recall(y_test, y_pred, 0.5)\n",
    "    return roc_auc, auc_pr, TP, TN, FP, FN, precision5, recall5, f15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the mapping as a list of tuples: (start_year, end_year, model_name)\n",
    "mapping = [\n",
    "    (2001, 2004, 'predict_2001_6yr_model'),\n",
    "    (2005, 2008, 'predict_2005_6yr_model'),\n",
    "    (2009, 2012, 'predict_2009_6yr_model'),\n",
    "    (2013, 2016, 'predict_2013_6yr_model'),\n",
    "    (2017, 2020, 'predict_2017_6yr_model'),\n",
    "    # Add more as needed\n",
    "]\n",
    "\n",
    "# Expand to a DataFrame: each prediction year mapped to its model\n",
    "lookup_rows = []\n",
    "for start, end, model in mapping:\n",
    "    for year in range(start, end + 1):\n",
    "        lookup_rows.append({'predict_year': year, 'model_name': model})\n",
    "\n",
    "lookup_df = pd.DataFrame(lookup_rows)\n",
    "\n",
    "# Example: get model for a given prediction year\n",
    "def get_model_for_year(year):\n",
    "    row = lookup_df.loc[lookup_df['predict_year'] == year]\n",
    "    if not row.empty:\n",
    "        return row['model_name'].values[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_2005_6yr_model\n"
     ]
    }
   ],
   "source": [
    "print(get_model_for_year(2006))  # Output: model_2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    predict_year              model_name\n",
      "0           2001  predict_2001_6yr_model\n",
      "1           2002  predict_2001_6yr_model\n",
      "2           2003  predict_2001_6yr_model\n",
      "3           2004  predict_2001_6yr_model\n",
      "4           2005  predict_2005_6yr_model\n",
      "5           2006  predict_2005_6yr_model\n",
      "6           2007  predict_2005_6yr_model\n",
      "7           2008  predict_2005_6yr_model\n",
      "8           2009  predict_2009_6yr_model\n",
      "9           2010  predict_2009_6yr_model\n",
      "10          2011  predict_2009_6yr_model\n",
      "11          2012  predict_2009_6yr_model\n",
      "12          2013  predict_2013_6yr_model\n",
      "13          2014  predict_2013_6yr_model\n",
      "14          2015  predict_2013_6yr_model\n",
      "15          2016  predict_2013_6yr_model\n",
      "16          2017  predict_2017_6yr_model\n",
      "17          2018  predict_2017_6yr_model\n",
      "18          2019  predict_2017_6yr_model\n",
      "19          2020  predict_2017_6yr_model\n"
     ]
    }
   ],
   "source": [
    "print(lookup_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing years: 100%|██████████| 20/20 [05:32<00:00, 16.61s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "log_messages = []\n",
    "log_messages.append(\"Model evaluation\")\n",
    "# add log to record the current time\n",
    "log_messages.append(f\"Start time: {pd.Timestamp.now()}\")\n",
    "# Define the range of years to predict\n",
    "years = range(2001, 2021)\n",
    "\n",
    "\n",
    "\n",
    "model_path = '../../Model/Extended_Data_Water_Year'\n",
    "\n",
    "save_predictions_path = '../../Clean_Data/Model_Data/Evaluation/Features_w_Label_w_pred/Extended_Data_Water_Year_4_year/parquet'\n",
    "if not os.path.exists(save_predictions_path):\n",
    "    os.makedirs(save_predictions_path)  \n",
    "\n",
    "# surpass the warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "input_path = '../../Clean_Data/Model_Data/Evaluation/Features_w_Label/Extended_Data_Water_Year'\n",
    "# Iterate over the years with a progress bar\n",
    "for year in tqdm(years, desc=\"Processing years\"):\n",
    "    log_messages.append(\"-\" * 50)\n",
    "    # log current water year\n",
    "    log_messages.append(f\"Predict Water Year: {year}\")\n",
    "    # read eval data, prev-year Oct - current year Sep\n",
    "    Eval_Human = pd.read_parquet(f'{input_path}/{year}_features_w_label.parquet')\n",
    "\n",
    "\n",
    "    cat_columns = ['wind_direction_category','veg']\n",
    "    Eval_Human = pd.get_dummies(Eval_Human, columns=cat_columns)\n",
    "\n",
    "    label_col = 'IS_FIRE'\n",
    "    model_name = get_model_for_year(year)\n",
    "    # load the model\n",
    "    with open(f'{model_path}/{model_name}.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    log_messages.append(f\"Model loaded: {model_name}\")\n",
    "    \n",
    "    features = model.get_booster().feature_names\n",
    "    # evaluate the model\n",
    "    roc_auc, auc_pr, TP, TN, FP, FN, precision5, recall5, f15 = evaluate_model(model, Eval_Human, features, label_col)\n",
    "    # append the results to the list\n",
    "    results.append([year, roc_auc, auc_pr, TP, TN, FP, FN, precision5, recall5, f15])\n",
    "\n",
    "    # add predictions to Eval_Human\n",
    "    Eval_Human['predictions'] = model.predict_proba(Eval_Human[features])[:, 1]\n",
    "    # save the predictions to a parquet file\n",
    "    Eval_Human.to_parquet(f'{save_predictions_path}/{year}_predictions.parquet', index=False)\n",
    "\n",
    "    del Eval_Human\n",
    "\n",
    "    # clean the cache\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the log messages to a log file\n",
    "with open('../../Logs/Clean_Extended_Data/model_eval_every_4_years.txt', 'w') as log_file:\n",
    "    log_file.write('\\n'.join(log_messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign column names to the results\n",
    "results_pd = pd.DataFrame(results, columns=['Year', 'ROC_AUC', 'AUC_PR', 'TP', 'TN', 'FP', 'FN', 'Precision_0.5', 'Recall_0.5', 'F1_0.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>AUC_PR</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Precision_0.5</th>\n",
       "      <th>Recall_0.5</th>\n",
       "      <th>F1_0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.872694</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>121</td>\n",
       "      <td>4728417</td>\n",
       "      <td>1422</td>\n",
       "      <td>3653</td>\n",
       "      <td>0.078419</td>\n",
       "      <td>0.032061</td>\n",
       "      <td>0.045514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>0.868813</td>\n",
       "      <td>0.011271</td>\n",
       "      <td>104</td>\n",
       "      <td>4729854</td>\n",
       "      <td>1315</td>\n",
       "      <td>3618</td>\n",
       "      <td>0.073291</td>\n",
       "      <td>0.027942</td>\n",
       "      <td>0.040459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>0.870220</td>\n",
       "      <td>0.012786</td>\n",
       "      <td>95</td>\n",
       "      <td>4732845</td>\n",
       "      <td>1235</td>\n",
       "      <td>3249</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.028409</td>\n",
       "      <td>0.040650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>0.865636</td>\n",
       "      <td>0.010493</td>\n",
       "      <td>98</td>\n",
       "      <td>4743403</td>\n",
       "      <td>1425</td>\n",
       "      <td>3644</td>\n",
       "      <td>0.064347</td>\n",
       "      <td>0.026189</td>\n",
       "      <td>0.037227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>0.882640</td>\n",
       "      <td>0.023210</td>\n",
       "      <td>65</td>\n",
       "      <td>4728227</td>\n",
       "      <td>273</td>\n",
       "      <td>3319</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.019208</td>\n",
       "      <td>0.034927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2006</td>\n",
       "      <td>0.870209</td>\n",
       "      <td>0.027006</td>\n",
       "      <td>98</td>\n",
       "      <td>4719775</td>\n",
       "      <td>250</td>\n",
       "      <td>4113</td>\n",
       "      <td>0.281609</td>\n",
       "      <td>0.023272</td>\n",
       "      <td>0.042992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007</td>\n",
       "      <td>0.865026</td>\n",
       "      <td>0.029670</td>\n",
       "      <td>108</td>\n",
       "      <td>4687758</td>\n",
       "      <td>267</td>\n",
       "      <td>5074</td>\n",
       "      <td>0.288000</td>\n",
       "      <td>0.020841</td>\n",
       "      <td>0.038870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008</td>\n",
       "      <td>0.853905</td>\n",
       "      <td>0.021080</td>\n",
       "      <td>100</td>\n",
       "      <td>4697610</td>\n",
       "      <td>419</td>\n",
       "      <td>4416</td>\n",
       "      <td>0.192678</td>\n",
       "      <td>0.022143</td>\n",
       "      <td>0.039722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.882543</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>136</td>\n",
       "      <td>4705515</td>\n",
       "      <td>911</td>\n",
       "      <td>3286</td>\n",
       "      <td>0.129895</td>\n",
       "      <td>0.039743</td>\n",
       "      <td>0.060864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010</td>\n",
       "      <td>0.890455</td>\n",
       "      <td>0.015444</td>\n",
       "      <td>66</td>\n",
       "      <td>4717161</td>\n",
       "      <td>731</td>\n",
       "      <td>2839</td>\n",
       "      <td>0.082811</td>\n",
       "      <td>0.022719</td>\n",
       "      <td>0.035656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2011</td>\n",
       "      <td>0.894914</td>\n",
       "      <td>0.026242</td>\n",
       "      <td>90</td>\n",
       "      <td>4712726</td>\n",
       "      <td>472</td>\n",
       "      <td>2655</td>\n",
       "      <td>0.160142</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.054430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012</td>\n",
       "      <td>0.854419</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>105</td>\n",
       "      <td>4706278</td>\n",
       "      <td>1428</td>\n",
       "      <td>2995</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.033871</td>\n",
       "      <td>0.045327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013</td>\n",
       "      <td>0.868167</td>\n",
       "      <td>0.026761</td>\n",
       "      <td>128</td>\n",
       "      <td>4716540</td>\n",
       "      <td>1002</td>\n",
       "      <td>2695</td>\n",
       "      <td>0.113274</td>\n",
       "      <td>0.045342</td>\n",
       "      <td>0.064761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014</td>\n",
       "      <td>0.845504</td>\n",
       "      <td>0.021702</td>\n",
       "      <td>113</td>\n",
       "      <td>4732171</td>\n",
       "      <td>1205</td>\n",
       "      <td>2884</td>\n",
       "      <td>0.085736</td>\n",
       "      <td>0.037704</td>\n",
       "      <td>0.052375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015</td>\n",
       "      <td>0.858687</td>\n",
       "      <td>0.025341</td>\n",
       "      <td>101</td>\n",
       "      <td>4735370</td>\n",
       "      <td>723</td>\n",
       "      <td>2429</td>\n",
       "      <td>0.122573</td>\n",
       "      <td>0.039921</td>\n",
       "      <td>0.060227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.869390</td>\n",
       "      <td>0.032848</td>\n",
       "      <td>130</td>\n",
       "      <td>4744892</td>\n",
       "      <td>735</td>\n",
       "      <td>2659</td>\n",
       "      <td>0.150289</td>\n",
       "      <td>0.046612</td>\n",
       "      <td>0.071155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.891640</td>\n",
       "      <td>0.014942</td>\n",
       "      <td>60</td>\n",
       "      <td>4733227</td>\n",
       "      <td>435</td>\n",
       "      <td>2629</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.022313</td>\n",
       "      <td>0.037688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.866400</td>\n",
       "      <td>0.016676</td>\n",
       "      <td>72</td>\n",
       "      <td>4729913</td>\n",
       "      <td>411</td>\n",
       "      <td>2897</td>\n",
       "      <td>0.149068</td>\n",
       "      <td>0.024251</td>\n",
       "      <td>0.041715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.867783</td>\n",
       "      <td>0.008978</td>\n",
       "      <td>39</td>\n",
       "      <td>4732187</td>\n",
       "      <td>466</td>\n",
       "      <td>1873</td>\n",
       "      <td>0.077228</td>\n",
       "      <td>0.020397</td>\n",
       "      <td>0.032271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.864469</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>36</td>\n",
       "      <td>4729975</td>\n",
       "      <td>309</td>\n",
       "      <td>2302</td>\n",
       "      <td>0.104348</td>\n",
       "      <td>0.015398</td>\n",
       "      <td>0.026836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year   ROC_AUC    AUC_PR   TP       TN    FP    FN  Precision_0.5  \\\n",
       "0   2001  0.872694  0.015152  121  4728417  1422  3653       0.078419   \n",
       "1   2002  0.868813  0.011271  104  4729854  1315  3618       0.073291   \n",
       "2   2003  0.870220  0.012786   95  4732845  1235  3249       0.071429   \n",
       "3   2004  0.865636  0.010493   98  4743403  1425  3644       0.064347   \n",
       "4   2005  0.882640  0.023210   65  4728227   273  3319       0.192308   \n",
       "5   2006  0.870209  0.027006   98  4719775   250  4113       0.281609   \n",
       "6   2007  0.865026  0.029670  108  4687758   267  5074       0.288000   \n",
       "7   2008  0.853905  0.021080  100  4697610   419  4416       0.192678   \n",
       "8   2009  0.882543  0.023328  136  4705515   911  3286       0.129895   \n",
       "9   2010  0.890455  0.015444   66  4717161   731  2839       0.082811   \n",
       "10  2011  0.894914  0.026242   90  4712726   472  2655       0.160142   \n",
       "11  2012  0.854419  0.017647  105  4706278  1428  2995       0.068493   \n",
       "12  2013  0.868167  0.026761  128  4716540  1002  2695       0.113274   \n",
       "13  2014  0.845504  0.021702  113  4732171  1205  2884       0.085736   \n",
       "14  2015  0.858687  0.025341  101  4735370   723  2429       0.122573   \n",
       "15  2016  0.869390  0.032848  130  4744892   735  2659       0.150289   \n",
       "16  2017  0.891640  0.014942   60  4733227   435  2629       0.121212   \n",
       "17  2018  0.866400  0.016676   72  4729913   411  2897       0.149068   \n",
       "18  2019  0.867783  0.008978   39  4732187   466  1873       0.077228   \n",
       "19  2020  0.864469  0.009014   36  4729975   309  2302       0.104348   \n",
       "\n",
       "    Recall_0.5    F1_0.5  \n",
       "0     0.032061  0.045514  \n",
       "1     0.027942  0.040459  \n",
       "2     0.028409  0.040650  \n",
       "3     0.026189  0.037227  \n",
       "4     0.019208  0.034927  \n",
       "5     0.023272  0.042992  \n",
       "6     0.020841  0.038870  \n",
       "7     0.022143  0.039722  \n",
       "8     0.039743  0.060864  \n",
       "9     0.022719  0.035656  \n",
       "10    0.032787  0.054430  \n",
       "11    0.033871  0.045327  \n",
       "12    0.045342  0.064761  \n",
       "13    0.037704  0.052375  \n",
       "14    0.039921  0.060227  \n",
       "15    0.046612  0.071155  \n",
       "16    0.022313  0.037688  \n",
       "17    0.024251  0.041715  \n",
       "18    0.020397  0.032271  \n",
       "19    0.015398  0.026836  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del all variables to free up memory\n",
    "del mod_Human\n",
    "del results\n",
    "del results_pd\n",
    "# clean the cache\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all data\n",
    "for name in dir():\n",
    "    if not name.startswith('_'):\n",
    "        del globals()[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing years: 100%|██████████| 20/20 [55:13<00:00, 165.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# save all parquet to csv\n",
    "years = range(2001, 2021)\n",
    "\n",
    "input_path = '../../Clean_Data/Model_Data/Evaluation/Features_w_Label_w_pred/Extended_Data_Water_Year/parquet'\n",
    "output_path = '../../Clean_Data/Model_Data/Evaluation/Features_w_Label_w_pred/Extended_Data_Water_Year/csv'\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "for year in tqdm(years, desc=\"Processing years\"):\n",
    "    # read the parquet file\n",
    "    df = pd.read_parquet(f'{input_path}/{year}_predictions.parquet')  \n",
    "    # write to csv\n",
    "    df.to_csv(f'{output_path}/{year}_predictions.csv', index=False)\n",
    "\n",
    "    # clean up the dataframes\n",
    "    del df\n",
    "    # clean the cache\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
