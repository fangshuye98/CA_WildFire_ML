{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove another 3 veg\n",
    "\n",
    "https://github.com/fangshuye98/CA_WildFire_ML/issues/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Force garbage collection\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_recall_curve,auc\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas version\n",
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "# check python version and all packages version\n",
    "def check_python_version():\n",
    "    import sys\n",
    "    print(\"Python version\")\n",
    "    print (sys.version)\n",
    "    print(\"Pandas version\")\n",
    "    print(pd.__version__)\n",
    "\n",
    "check_python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_features = ['dead_fuel_moisture_1000hr',\n",
    "       'dead_fuel_moisture_100hr', \n",
    "       'max_air_temperature', 'max_relative_humidity', \n",
    "       'min_air_temperature', 'min_relative_humidity', 'precipitation_amount',\n",
    "       'specific_humidity', 'surface_downwelling_shortwave_flux_in_air',\n",
    "       #'wind_from_direction', \n",
    "       'wind_speed', 'wind_direction_category', 'SWE',\n",
    "       #'population_density',\n",
    "       'LAI', \n",
    "       #'pdsi', \n",
    "       #'IS_FIRE', \n",
    "       #'min_FIRE_SIZE', 'max_FIRE_SIZE', 'Year','fire_attribute', \n",
    "       #'veg', \n",
    "       'veg_group',\n",
    "       #'slope_avg', \n",
    "       'slope_max',\n",
    "       'road_density_km_km2',\n",
    "       'line_density_km_per_cell' \n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, features, label_col):\n",
    "    X_train = train_data[features]\n",
    "    y_train = train_data[label_col]\n",
    "    # train the model\n",
    "    model = xgb.XGBClassifier(eval_metric='logloss', tree_method='hist')\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# define function to calculate precision and recall based on a threshold\n",
    "def calculate_precision_recall(y_true, y_pred_proba, threshold, print_output=False):\n",
    "    y_pred = (y_pred_proba > threshold).astype(int)\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "    precision = confusion[1, 1] / (confusion[1, 1] + confusion[0, 1])\n",
    "    recall = confusion[1, 1] / (confusion[1, 1] + confusion[1, 0])\n",
    "    # F1 score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    if print_output:\n",
    "        print(f'Threshold: {threshold:.2f}')\n",
    "        print(f'Precision: {precision * 100:.2f}%')\n",
    "        print(f'Recall: {recall * 100:.2f}%')\n",
    "        print(\"Confusion Matrix\")\n",
    "        print(pd.DataFrame(confusion, index=['True Neg', 'True Pos'], columns=['Pred Neg', 'Pred Pos']))\n",
    "    # get TP, TN, FP, FN\n",
    "    TP = confusion[1, 1]\n",
    "    TN = confusion[0, 0]\n",
    "    FP = confusion[0, 1]\n",
    "    FN = confusion[1, 0]\n",
    "    return TP, TN, FP, FN, precision, recall, f1\n",
    "\n",
    "def evaluate_model(model, test_data, features, label_col):\n",
    "    X_test = test_data[features]\n",
    "    y_test = test_data[label_col]\n",
    "    # predict the probability of fire\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    # calculate the roc_auc_score\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    # print roc_auc in a sentence\n",
    "    # print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "    # Calculate precision and recall values\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "    # Calculate the area under the precision-recall curve\n",
    "    auc_pr = auc(recall, precision)\n",
    "    # print(f\"Area Under Precision-Recall Curve (AUC-PR): {auc_pr:.2f}\")\n",
    "    # calculate precision and recall at thresholds 0.5\n",
    "    TP, TN, FP, FN, precision5, recall5, f15 = calculate_precision_recall(y_test, y_pred, 0.5)\n",
    "    return roc_auc, auc_pr, TP, TN, FP, FN, precision5, recall5, f15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Water Years 2007 using training data: 2000-10-01 00:00:00 ~ 2006-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "def get_water_year_range(target_year, num_years=6):\n",
    "    min_year = target_year - num_years - 1\n",
    "    min_day = f\"{min_year}-10-01 00:00:00\"\n",
    "    max_day = f\"{target_year-1}-09-30 00:00:00\"\n",
    "    return min_day, max_day\n",
    "\n",
    "# Example: Get range for Water Year 2007\n",
    "target_year = 2007\n",
    "min_day, max_day = get_water_year_range(target_year)\n",
    "\n",
    "print(f\"Predict Water Years {target_year} using training data: {min_day} ~ {max_day}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = \"Extended_Data_Water_Year_no_riparian_desert_wetland_barren_group_veg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing years: 100%|██████████| 20/20 [07:37<00:00, 22.86s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "log_messages = []\n",
    "log_messages.append(\"Model Version: Remove Desert, Wetland, Barren Group Veg\")\n",
    "# add log to record the current time\n",
    "log_messages.append(f\"Start time: {pd.Timestamp.now()}\")\n",
    "# Define the range of years to predict\n",
    "years = range(2001, 2021)\n",
    "\n",
    "\n",
    "# Plot\n",
    "model_path = f'../../Model/{model_version}'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "save_predictions_path = f'../../Clean_Data/Model_Data/Evaluation/Features_w_Label_w_pred/{model_version}/parquet'\n",
    "if not os.path.exists(save_predictions_path):\n",
    "    os.makedirs(save_predictions_path)  \n",
    "\n",
    "# surpass the warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "file_name = 'features_w_label_downsample_1994_2020_no_riparian_desert_wetland_barren_group_veg.parquet'\n",
    "mod_Human = pd.read_parquet(f'../../Clean_Data/Model_Data/Downsample/Features_w_Label/{file_name}')\n",
    "\n",
    "input_path = f'../../Clean_Data/Model_Data/Evaluation/Features_w_Label/{model_version}'\n",
    "# Iterate over the years with a progress bar\n",
    "for year in tqdm(years, desc=\"Processing years\"):\n",
    "    log_messages.append(\"-\" * 50)\n",
    "    # log current water year\n",
    "    log_messages.append(f\"Processing Water Year: {year}\")\n",
    "    # read eval data, prev-year Oct - current year Sep\n",
    "    Eval_Human = pd.read_parquet(f'{input_path}/{year}_features_w_label.parquet')\n",
    "\n",
    "    # get water year range\n",
    "    min_day, max_day = get_water_year_range(year)\n",
    "    # filter the training data\n",
    "    train_data = mod_Human[(mod_Human['day'] >= min_day) & (mod_Human['day'] <= max_day)]\n",
    "    # use log message to show the min and max of day from mod_Human\n",
    "    log_messages.append(f\"Training Data Day min: {train_data['day'].min()}, max: {train_data['day'].max()}\")\n",
    "    #mod_Human = mod_Human[features_to_keep]\n",
    "    #Eval_Human = Eval_Human[features_to_keep]\n",
    "\n",
    "    cat_columns = ['wind_direction_category','veg_group']\n",
    "\n",
    "    # one hot encoding\n",
    "    train_data = pd.get_dummies(train_data, columns=cat_columns)\n",
    "    Eval_Human = pd.get_dummies(Eval_Human, columns=cat_columns)\n",
    "\n",
    "    # extract column names starting with 'wind_direction_category_' and 'veg_'\n",
    "    wind_direction_category_cols = [col for col in train_data.columns if col.startswith('wind_direction_category_')]\n",
    "    veg_cols = [col for col in train_data.columns if col.startswith('veg_group_') and col != 'veg_type_details']\n",
    "\n",
    "    features = initial_features + wind_direction_category_cols + veg_cols\n",
    "    # drop cat_columns from features\n",
    "    features = [col for col in features if col not in cat_columns]\n",
    "\n",
    "    label_col = 'IS_FIRE'\n",
    "    model = train_model(train_data, features, label_col)\n",
    "    # save model to a pickle file\n",
    "    with open(f'{model_path}/predict_{year}_6yr_model.pkl', 'wb') as f:\n",
    "         pickle.dump(model, f)\n",
    "    # save model to ../../Model/predict_year\n",
    "    # model.save_model(f'../../Model/predict_{year}_6yr_model.json')\n",
    "    # evaluate the model\n",
    "    roc_auc, auc_pr, TP, TN, FP, FN, precision5, recall5, f15 = evaluate_model(model, Eval_Human, features, label_col)\n",
    "    # append the results to the list\n",
    "    results.append([year, roc_auc, auc_pr, TP, TN, FP, FN, precision5, recall5, f15])\n",
    "\n",
    "    # add predictions to Eval_Human\n",
    "    Eval_Human['predictions'] = model.predict_proba(Eval_Human[features])[:, 1]\n",
    "    # save the predictions to a parquet file\n",
    "    Eval_Human.to_parquet(f'{save_predictions_path}/{year}_predictions.parquet', index=False)\n",
    "\n",
    "    # clean up the dataframes\n",
    "    del train_data\n",
    "    del Eval_Human\n",
    "\n",
    "    # clean the cache\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the log messages to a log file\n",
    "with open('../../Logs/Clean_Extended_Data/model_training_6_years_no_4.txt', 'w') as log_file:\n",
    "    log_file.write('\\n'.join(log_messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign column names to the results\n",
    "results_pd = pd.DataFrame(results, columns=['Year', 'ROC_AUC', 'AUC_PR', 'TP', 'TN', 'FP', 'FN', 'Precision_0.5', 'Recall_0.5', 'F1_0.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>AUC_PR</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Precision_0.5</th>\n",
       "      <th>Recall_0.5</th>\n",
       "      <th>F1_0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.851925</td>\n",
       "      <td>0.026811</td>\n",
       "      <td>113</td>\n",
       "      <td>4280368</td>\n",
       "      <td>898</td>\n",
       "      <td>3455</td>\n",
       "      <td>0.111771</td>\n",
       "      <td>0.031670</td>\n",
       "      <td>0.049356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>0.845683</td>\n",
       "      <td>0.027212</td>\n",
       "      <td>104</td>\n",
       "      <td>4280837</td>\n",
       "      <td>721</td>\n",
       "      <td>3434</td>\n",
       "      <td>0.126061</td>\n",
       "      <td>0.029395</td>\n",
       "      <td>0.047674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>0.857041</td>\n",
       "      <td>0.022475</td>\n",
       "      <td>87</td>\n",
       "      <td>4283805</td>\n",
       "      <td>519</td>\n",
       "      <td>3083</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>0.027445</td>\n",
       "      <td>0.046081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>0.845976</td>\n",
       "      <td>0.020466</td>\n",
       "      <td>76</td>\n",
       "      <td>4293443</td>\n",
       "      <td>486</td>\n",
       "      <td>3472</td>\n",
       "      <td>0.135231</td>\n",
       "      <td>0.021421</td>\n",
       "      <td>0.036983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>0.876894</td>\n",
       "      <td>0.024112</td>\n",
       "      <td>68</td>\n",
       "      <td>4281165</td>\n",
       "      <td>296</td>\n",
       "      <td>2968</td>\n",
       "      <td>0.186813</td>\n",
       "      <td>0.022398</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2006</td>\n",
       "      <td>0.866117</td>\n",
       "      <td>0.025359</td>\n",
       "      <td>82</td>\n",
       "      <td>4274194</td>\n",
       "      <td>265</td>\n",
       "      <td>3690</td>\n",
       "      <td>0.236311</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.039815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007</td>\n",
       "      <td>0.852753</td>\n",
       "      <td>0.030601</td>\n",
       "      <td>115</td>\n",
       "      <td>4243446</td>\n",
       "      <td>320</td>\n",
       "      <td>4622</td>\n",
       "      <td>0.264368</td>\n",
       "      <td>0.024277</td>\n",
       "      <td>0.044470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008</td>\n",
       "      <td>0.842053</td>\n",
       "      <td>0.025183</td>\n",
       "      <td>125</td>\n",
       "      <td>4251981</td>\n",
       "      <td>577</td>\n",
       "      <td>3971</td>\n",
       "      <td>0.178063</td>\n",
       "      <td>0.030518</td>\n",
       "      <td>0.052105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.859147</td>\n",
       "      <td>0.019722</td>\n",
       "      <td>92</td>\n",
       "      <td>4260365</td>\n",
       "      <td>697</td>\n",
       "      <td>2985</td>\n",
       "      <td>0.116603</td>\n",
       "      <td>0.029899</td>\n",
       "      <td>0.047594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010</td>\n",
       "      <td>0.867834</td>\n",
       "      <td>0.012908</td>\n",
       "      <td>62</td>\n",
       "      <td>4271238</td>\n",
       "      <td>558</td>\n",
       "      <td>2496</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.024238</td>\n",
       "      <td>0.039018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2011</td>\n",
       "      <td>0.873495</td>\n",
       "      <td>0.027390</td>\n",
       "      <td>97</td>\n",
       "      <td>4266349</td>\n",
       "      <td>537</td>\n",
       "      <td>2340</td>\n",
       "      <td>0.152997</td>\n",
       "      <td>0.039803</td>\n",
       "      <td>0.063172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012</td>\n",
       "      <td>0.830620</td>\n",
       "      <td>0.019050</td>\n",
       "      <td>99</td>\n",
       "      <td>4259350</td>\n",
       "      <td>1057</td>\n",
       "      <td>2780</td>\n",
       "      <td>0.085640</td>\n",
       "      <td>0.034387</td>\n",
       "      <td>0.049071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013</td>\n",
       "      <td>0.840488</td>\n",
       "      <td>0.025801</td>\n",
       "      <td>105</td>\n",
       "      <td>4268948</td>\n",
       "      <td>836</td>\n",
       "      <td>2549</td>\n",
       "      <td>0.111583</td>\n",
       "      <td>0.039563</td>\n",
       "      <td>0.058414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014</td>\n",
       "      <td>0.810640</td>\n",
       "      <td>0.021728</td>\n",
       "      <td>97</td>\n",
       "      <td>4283362</td>\n",
       "      <td>605</td>\n",
       "      <td>2741</td>\n",
       "      <td>0.138177</td>\n",
       "      <td>0.034179</td>\n",
       "      <td>0.054802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015</td>\n",
       "      <td>0.823737</td>\n",
       "      <td>0.017944</td>\n",
       "      <td>77</td>\n",
       "      <td>4286166</td>\n",
       "      <td>304</td>\n",
       "      <td>2301</td>\n",
       "      <td>0.202100</td>\n",
       "      <td>0.032380</td>\n",
       "      <td>0.055817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.847128</td>\n",
       "      <td>0.036840</td>\n",
       "      <td>121</td>\n",
       "      <td>4295624</td>\n",
       "      <td>264</td>\n",
       "      <td>2451</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.047045</td>\n",
       "      <td>0.081840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.867111</td>\n",
       "      <td>0.014322</td>\n",
       "      <td>64</td>\n",
       "      <td>4284296</td>\n",
       "      <td>380</td>\n",
       "      <td>2451</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.025447</td>\n",
       "      <td>0.043258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.834610</td>\n",
       "      <td>0.016552</td>\n",
       "      <td>68</td>\n",
       "      <td>4282933</td>\n",
       "      <td>275</td>\n",
       "      <td>2606</td>\n",
       "      <td>0.198251</td>\n",
       "      <td>0.025430</td>\n",
       "      <td>0.045078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.840432</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>34</td>\n",
       "      <td>4285209</td>\n",
       "      <td>288</td>\n",
       "      <td>1631</td>\n",
       "      <td>0.105590</td>\n",
       "      <td>0.020420</td>\n",
       "      <td>0.034222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.848106</td>\n",
       "      <td>0.011873</td>\n",
       "      <td>43</td>\n",
       "      <td>4281825</td>\n",
       "      <td>299</td>\n",
       "      <td>2044</td>\n",
       "      <td>0.125731</td>\n",
       "      <td>0.020604</td>\n",
       "      <td>0.035406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year   ROC_AUC    AUC_PR   TP       TN    FP    FN  Precision_0.5  \\\n",
       "0   2001  0.851925  0.026811  113  4280368   898  3455       0.111771   \n",
       "1   2002  0.845683  0.027212  104  4280837   721  3434       0.126061   \n",
       "2   2003  0.857041  0.022475   87  4283805   519  3083       0.143564   \n",
       "3   2004  0.845976  0.020466   76  4293443   486  3472       0.135231   \n",
       "4   2005  0.876894  0.024112   68  4281165   296  2968       0.186813   \n",
       "5   2006  0.866117  0.025359   82  4274194   265  3690       0.236311   \n",
       "6   2007  0.852753  0.030601  115  4243446   320  4622       0.264368   \n",
       "7   2008  0.842053  0.025183  125  4251981   577  3971       0.178063   \n",
       "8   2009  0.859147  0.019722   92  4260365   697  2985       0.116603   \n",
       "9   2010  0.867834  0.012908   62  4271238   558  2496       0.100000   \n",
       "10  2011  0.873495  0.027390   97  4266349   537  2340       0.152997   \n",
       "11  2012  0.830620  0.019050   99  4259350  1057  2780       0.085640   \n",
       "12  2013  0.840488  0.025801  105  4268948   836  2549       0.111583   \n",
       "13  2014  0.810640  0.021728   97  4283362   605  2741       0.138177   \n",
       "14  2015  0.823737  0.017944   77  4286166   304  2301       0.202100   \n",
       "15  2016  0.847128  0.036840  121  4295624   264  2451       0.314286   \n",
       "16  2017  0.867111  0.014322   64  4284296   380  2451       0.144144   \n",
       "17  2018  0.834610  0.016552   68  4282933   275  2606       0.198251   \n",
       "18  2019  0.840432  0.010482   34  4285209   288  1631       0.105590   \n",
       "19  2020  0.848106  0.011873   43  4281825   299  2044       0.125731   \n",
       "\n",
       "    Recall_0.5    F1_0.5  \n",
       "0     0.031670  0.049356  \n",
       "1     0.029395  0.047674  \n",
       "2     0.027445  0.046081  \n",
       "3     0.021421  0.036983  \n",
       "4     0.022398  0.040000  \n",
       "5     0.021739  0.039815  \n",
       "6     0.024277  0.044470  \n",
       "7     0.030518  0.052105  \n",
       "8     0.029899  0.047594  \n",
       "9     0.024238  0.039018  \n",
       "10    0.039803  0.063172  \n",
       "11    0.034387  0.049071  \n",
       "12    0.039563  0.058414  \n",
       "13    0.034179  0.054802  \n",
       "14    0.032380  0.055817  \n",
       "15    0.047045  0.081840  \n",
       "16    0.025447  0.043258  \n",
       "17    0.025430  0.045078  \n",
       "18    0.020420  0.034222  \n",
       "19    0.020604  0.035406  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del all variables to free up memory\n",
    "del mod_Human\n",
    "del results\n",
    "del results_pd\n",
    "# clean the cache\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
