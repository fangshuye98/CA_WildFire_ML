{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import pyproj\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas version\n",
      "2.2.2\n",
      "Pyproj version\n",
      "3.6.1\n"
     ]
    }
   ],
   "source": [
    "# check python version and all packages version\n",
    "def check_python_version():\n",
    "    import sys\n",
    "    print(\"Python version\")\n",
    "    print (sys.version)\n",
    "    print(\"Pandas version\")\n",
    "    print(pd.__version__)\n",
    "    print(\"Pyproj version\")\n",
    "    print(pyproj.__version__)\n",
    "\n",
    "check_python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Force garbage collection\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../../Clean_Data/Extended_Feature_Data/'\n",
    "file_name =  'Weather_Data_w_Veg_SubRegion_Filter_Merged_Add_population_lai_Completed.parquet'\n",
    "features = pd.read_parquet(input_path + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day                                          datetime64[ns]\n",
       "lat                                                 float64\n",
       "lon                                                 float64\n",
       "SWE                                                 float32\n",
       "year                                                  int32\n",
       "dead_fuel_moisture_1000hr                           float32\n",
       "dead_fuel_moisture_100hr                            float32\n",
       "max_air_temperature                                 float64\n",
       "max_relative_humidity                               float32\n",
       "min_air_temperature                                 float64\n",
       "min_relative_humidity                               float32\n",
       "precipitation_amount                                float32\n",
       "specific_humidity                                   float32\n",
       "surface_downwelling_shortwave_flux_in_air           float32\n",
       "wind_from_direction                                 float32\n",
       "wind_speed                                          float32\n",
       "population_density                                  float64\n",
       "LAI                                                 float64\n",
       "wind_direction_category                            category\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127137467, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day                                          0.0\n",
       "lat                                          0.0\n",
       "lon                                          0.0\n",
       "SWE                                          0.0\n",
       "year                                         0.0\n",
       "dead_fuel_moisture_1000hr                    0.0\n",
       "dead_fuel_moisture_100hr                     0.0\n",
       "max_air_temperature                          0.0\n",
       "max_relative_humidity                        0.0\n",
       "min_air_temperature                          0.0\n",
       "min_relative_humidity                        0.0\n",
       "precipitation_amount                         0.0\n",
       "specific_humidity                            0.0\n",
       "surface_downwelling_shortwave_flux_in_air    0.0\n",
       "wind_from_direction                          0.0\n",
       "wind_speed                                   0.0\n",
       "population_density                           0.0\n",
       "LAI                                          0.0\n",
       "wind_direction_category                      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing rate\n",
    "features.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('1994-01-01 00:00:00'), Timestamp('2020-09-30 00:00:00'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check range of day\n",
    "features['day'].min(), features['day'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge static features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_data = pd.read_parquet('../../Clean_Data/lon_lat_pair_weather_match_veg_v2.parquet')\n",
    "slope_data = pd.read_parquet('../../Clean_Data/lon_lat_pair_weather_match_slope.parquet')\n",
    "road_density_data = pd.read_parquet('../../Clean_Data/road_density_match_weather_grid.parquet')\n",
    "\n",
    "# newly added in extended data\n",
    "powerline_data = pd.read_parquet('../../Clean_Data/Extended_Data_w_Veg_Filter/Powerline/transmission_line_density.parquet')\n",
    "subregion_data = pd.read_parquet('../../Clean_Data/Extended_Data_w_Veg_Filter/SubRegion/lon_lat_pair_weather_match_subregion.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vegetation data shape: (17703, 7)\n",
      "Slope data shape: (62160, 5)\n",
      "Road density data shape: (17703, 4)\n",
      "Powerline data shape: (14383, 3)\n",
      "Subregion data shape: (13048, 3)\n"
     ]
    }
   ],
   "source": [
    "# print shape of each data into a sentence\n",
    "print(f\"Vegetation data shape: {veg_data.shape}\")\n",
    "print(f\"Slope data shape: {slope_data.shape}\")\n",
    "print(f\"Road density data shape: {road_density_data.shape}\")\n",
    "print(f\"Powerline data shape: {powerline_data.shape}\")\n",
    "print(f\"Subregion data shape: {subregion_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_data = veg_data[['lon', 'lat','fire_attribute','veg']]\n",
    "slope_data = slope_data[['lon', 'lat', 'slope_avg', 'slope_max']]\n",
    "road_density_data = road_density_data[['lon', 'lat', 'road_density_km_km2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join 5 data on lon and lat in a for loop\n",
    "data_list = [veg_data, slope_data, road_density_data, powerline_data, subregion_data]\n",
    "\n",
    "static_features = subregion_data[['lon', 'lat']].drop_duplicates()\n",
    "for data in data_list:\n",
    "    # assert error if lon and lat are not unique\n",
    "    if not data[['lon', 'lat']].drop_duplicates().shape[0] == data.shape[0]:\n",
    "        raise ValueError(f\"Data contains non-unique lon and lat pairs: {data.shape}\") \n",
    "    static_features = static_features.merge(data, on=['lon', 'lat'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13048, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lon', 'lat', 'fire_attribute', 'veg', 'slope_avg', 'slope_max',\n",
       "       'road_density_km_km2', 'line_density_km_per_cell', 'SubRegion'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write it to ../../Clean_Data/static_features.parquet\n",
    "static_features.to_parquet('../../Clean_Data/static_features.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge daily feature w static features and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../../Clean_Data/Model_Data/Downsample/Fire_Label'\n",
    "file_name = 'calfire_fod_fpa_1994_2000_fire_label_downsampled.parquet'\n",
    "fire_label = pd.read_parquet(save_path + '/' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lon', 'lat', 'day', 'IS_FIRE', 'min_FIRE_SIZE', 'max_FIRE_SIZE'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_label.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('1994-01-01 00:00:00'), Timestamp('2020-09-30 00:00:00'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['day'].min(), features['day'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('1994-01-01 00:00:00'), Timestamp('2020-12-31 00:00:00'))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_label['day'].min(), fire_label['day'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((127137467, 19), (9292000, 6))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, fire_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_data = pd.merge(features, fire_label, on=['lon', 'lat', 'day'], how='inner')\n",
    "mod_data = pd.merge(mod_data, static_features, on=['lon', 'lat'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9180502, 29)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['day', 'lat', 'lon', 'SWE', 'year', 'dead_fuel_moisture_1000hr',\n",
       "       'dead_fuel_moisture_100hr', 'max_air_temperature',\n",
       "       'max_relative_humidity', 'min_air_temperature', 'min_relative_humidity',\n",
       "       'precipitation_amount', 'specific_humidity',\n",
       "       'surface_downwelling_shortwave_flux_in_air', 'wind_from_direction',\n",
       "       'wind_speed', 'population_density', 'LAI', 'wind_direction_category',\n",
       "       'IS_FIRE', 'min_FIRE_SIZE', 'max_FIRE_SIZE', 'fire_attribute', 'veg',\n",
       "       'slope_avg', 'slope_max', 'road_density_km_km2',\n",
       "       'line_density_km_per_cell', 'SubRegion'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 29)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that no water, urban, or agriculture in veg\n",
    "data_check = mod_data[mod_data['veg'].str.contains('Water|Urban|Agriculture')]\n",
    "data_check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Native Coastal Sage Scrub ', 'Native Conifer Forest ',\n",
       "       'Native Grassland ', 'Native Chapparal ', 'Native Desert ',\n",
       "       'Riparian ', 'Native Inland Scrub ', 'Native Conifer Alpine ',\n",
       "       'Non-native forest ', 'Non-native grassland ', 'Barren ',\n",
       "       'Native Wetland ', 'Non-native shrub ', 'Native Oak Woodland '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_data['veg'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IS_FIRE\n",
       "0    0.990047\n",
       "1    0.009953\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_data['IS_FIRE'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_data.to_parquet(f\"../../Clean_Data/Model_Data/Downsample/Features_w_Label/features_w_label_downsample_1994_2020.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove riparian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_data = pd.read_parquet(f'../../Clean_Data/Model_Data/Downsample/Features_w_Label/features_w_label_downsample_1994_2020.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove veg containing 'Riparian'\n",
    "mod_data = mod_data[~mod_data['veg'].str.contains('Riparian')]\n",
    "save_path = '../../Clean_Data/Model_Data/Downsample/Features_w_Label'\n",
    "mod_data.to_parquet(f\"{save_path}/features_w_label_downsample_1994_2020_no_riparian.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mod_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each Water Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read static features\n",
    "static_features = pd.read_parquet('../../Clean_Data/static_features.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Water years: 100%|██████████| 26/26 [36:29<00:00, 84.23s/it]\n"
     ]
    }
   ],
   "source": [
    "log_messages = []\n",
    "# append current timestamp to log_messages\n",
    "log_messages.append(f\"Log messages for processing water years feature merge label: {pd.Timestamp.now()}\")\n",
    "\n",
    "file_path = '../../Clean_Data/Model_Data/Evaluation/Fire_Label/Water_Year'\n",
    "save_path = '../../Clean_Data/Model_Data/Evaluation/Features_w_Label/Extended_Data_Water_Year'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "for year in tqdm(range(1995, 2021), desc=\"Processing Water years\"):\n",
    "    # add separator line in log\n",
    "    log_messages.append(\"=\"*50)\n",
    "    log_messages.append(f\"Processing water year: {year}\")\n",
    "    file_name = os.path.join(file_path, f'calfire_fod_fpa_fire_label_wy_{year}.parquet')\n",
    "    fire_label = pd.read_parquet(file_name)\n",
    "\n",
    "    mod_data = pd.merge(features, fire_label, on=['lon', 'lat', 'day'], how='inner')\n",
    "    mod_data = pd.merge(mod_data, static_features, on=['lon', 'lat'], how='inner')\n",
    "\n",
    "    start_date = pd.Timestamp(year=year -1, month=10, day=1)\n",
    "    end_date = pd.Timestamp(year=year, month=9, day=30)\n",
    "    mod_data = mod_data[(mod_data['day'] >= start_date) & (mod_data['day'] <= end_date)]\n",
    "\n",
    "    log_message = f\"Feature w label data saved, min day: {mod_data['day'].min()}, max day: {mod_data['day'].max()}\"\n",
    "    log_messages.append(log_message)\n",
    "\n",
    "    # save to parquet\n",
    "    mod_data.to_parquet(f\"{save_path}/{year}_features_w_label.parquet\")\n",
    "    log_messages.append(f\"Data saved for year {year} with shape: {mod_data.shape}\")\n",
    "    log_messages.append(f\"Saved path: {save_path}/{year}_features_w_label.parquet\")\n",
    "\n",
    "    gc.collect()\n",
    "    # free up memory\n",
    "    del mod_data, fire_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the log messages to a log file\n",
    "with open('../../Logs/Clean_Extended_Data/water_year_evaluation_data_log.txt', 'w') as log_file:\n",
    "    log_file.write('\\n'.join(log_messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing Water Years: 100%|██████████| 26/26 [00:53<00:00,  2.04s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []  # Use a list instead of DataFrame\n",
    "save_path = '../../Clean_Data/Model_Data/Evaluation/Features_w_Label/Extended_Data_Water_Year'\n",
    "for year in tqdm(range(1995, 2021), desc=\"Summarizing Water Years\"):\n",
    "\n",
    "    fire_label_path = os.path.join(save_path, f'{year}_features_w_label.parquet')\n",
    "    mod_data = pd.read_parquet(fire_label_path)\n",
    "    \n",
    "    # check missing rate of all columns\n",
    "    missing_rates = mod_data.isnull().mean()\n",
    "    # filter out columns with positive missing rate\n",
    "    missing_rates = missing_rates[missing_rates > 0]\n",
    "    if not missing_rates.empty:\n",
    "        print(f\"Missing rates for year {year}:\")\n",
    "        print(missing_rates)\n",
    "    \n",
    "    # count the number of fires\n",
    "    num_fires = mod_data['IS_FIRE'].sum()\n",
    "    total_rows = mod_data.shape[0]\n",
    "    \n",
    "    # calculate the percentage of fires\n",
    "    fire_percentage = (num_fires / total_rows) * 100\n",
    "    min_day, max_day = mod_data['day'].min(), mod_data['day'].max()\n",
    "\n",
    "    results.append({\n",
    "        'Water Year': year,\n",
    "        'Start Datetime': min_day,\n",
    "        'End Datetime': max_day,\n",
    "        'Total Rows': total_rows,\n",
    "        'Number of Fires': num_fires,\n",
    "        'Fire Percentage': fire_percentage\n",
    "    })\n",
    "\n",
    "result = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename last column to 'Fire Percentage (%)'\n",
    "result.rename(columns={'Fire Percentage': 'Fire Percentage (%)'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Water Year</th>\n",
       "      <th>Start Datetime</th>\n",
       "      <th>End Datetime</th>\n",
       "      <th>Total Rows</th>\n",
       "      <th>Number of Fires</th>\n",
       "      <th>Fire Percentage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995</td>\n",
       "      <td>1994-10-01</td>\n",
       "      <td>1995-09-30</td>\n",
       "      <td>4703262</td>\n",
       "      <td>3331</td>\n",
       "      <td>0.070823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996</td>\n",
       "      <td>1995-10-01</td>\n",
       "      <td>1996-09-30</td>\n",
       "      <td>4699385</td>\n",
       "      <td>4553</td>\n",
       "      <td>0.096885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997</td>\n",
       "      <td>1996-10-01</td>\n",
       "      <td>1997-09-30</td>\n",
       "      <td>4693711</td>\n",
       "      <td>3958</td>\n",
       "      <td>0.084326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>1997-10-01</td>\n",
       "      <td>1998-09-30</td>\n",
       "      <td>4714847</td>\n",
       "      <td>2859</td>\n",
       "      <td>0.060638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999</td>\n",
       "      <td>1998-10-01</td>\n",
       "      <td>1999-09-30</td>\n",
       "      <td>4703945</td>\n",
       "      <td>4183</td>\n",
       "      <td>0.088925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>1999-10-01</td>\n",
       "      <td>2000-09-30</td>\n",
       "      <td>4736858</td>\n",
       "      <td>3785</td>\n",
       "      <td>0.079905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2001</td>\n",
       "      <td>2000-10-01</td>\n",
       "      <td>2001-09-30</td>\n",
       "      <td>4733613</td>\n",
       "      <td>3774</td>\n",
       "      <td>0.079728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2002</td>\n",
       "      <td>2001-10-01</td>\n",
       "      <td>2002-09-30</td>\n",
       "      <td>4734891</td>\n",
       "      <td>3722</td>\n",
       "      <td>0.078608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2003</td>\n",
       "      <td>2002-10-01</td>\n",
       "      <td>2003-09-30</td>\n",
       "      <td>4737424</td>\n",
       "      <td>3344</td>\n",
       "      <td>0.070587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2004</td>\n",
       "      <td>2003-10-01</td>\n",
       "      <td>2004-09-30</td>\n",
       "      <td>4748570</td>\n",
       "      <td>3742</td>\n",
       "      <td>0.078803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2005</td>\n",
       "      <td>2004-10-01</td>\n",
       "      <td>2005-09-30</td>\n",
       "      <td>4731884</td>\n",
       "      <td>3384</td>\n",
       "      <td>0.071515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2006</td>\n",
       "      <td>2005-10-01</td>\n",
       "      <td>2006-09-30</td>\n",
       "      <td>4724236</td>\n",
       "      <td>4211</td>\n",
       "      <td>0.089136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2007</td>\n",
       "      <td>2006-10-01</td>\n",
       "      <td>2007-09-30</td>\n",
       "      <td>4693207</td>\n",
       "      <td>5182</td>\n",
       "      <td>0.110415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2008</td>\n",
       "      <td>2007-10-01</td>\n",
       "      <td>2008-09-30</td>\n",
       "      <td>4702545</td>\n",
       "      <td>4516</td>\n",
       "      <td>0.096033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2009</td>\n",
       "      <td>2008-10-01</td>\n",
       "      <td>2009-09-30</td>\n",
       "      <td>4709848</td>\n",
       "      <td>3422</td>\n",
       "      <td>0.072656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2010</td>\n",
       "      <td>2009-10-01</td>\n",
       "      <td>2010-09-30</td>\n",
       "      <td>4720797</td>\n",
       "      <td>2905</td>\n",
       "      <td>0.061536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2011</td>\n",
       "      <td>2010-10-01</td>\n",
       "      <td>2011-09-30</td>\n",
       "      <td>4715943</td>\n",
       "      <td>2745</td>\n",
       "      <td>0.058207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2012</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>4710806</td>\n",
       "      <td>3100</td>\n",
       "      <td>0.065806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2013</td>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>4720365</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.059805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2014</td>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>2014-09-30</td>\n",
       "      <td>4736373</td>\n",
       "      <td>2997</td>\n",
       "      <td>0.063276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2015</td>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>2015-09-30</td>\n",
       "      <td>4738623</td>\n",
       "      <td>2530</td>\n",
       "      <td>0.053391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2016</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>4748416</td>\n",
       "      <td>2789</td>\n",
       "      <td>0.058735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>4736351</td>\n",
       "      <td>2689</td>\n",
       "      <td>0.056774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>4733293</td>\n",
       "      <td>2969</td>\n",
       "      <td>0.062726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>4734565</td>\n",
       "      <td>1912</td>\n",
       "      <td>0.040384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>4732622</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.049402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Water Year Start Datetime End Datetime  Total Rows  Number of Fires  \\\n",
       "0         1995     1994-10-01   1995-09-30     4703262             3331   \n",
       "1         1996     1995-10-01   1996-09-30     4699385             4553   \n",
       "2         1997     1996-10-01   1997-09-30     4693711             3958   \n",
       "3         1998     1997-10-01   1998-09-30     4714847             2859   \n",
       "4         1999     1998-10-01   1999-09-30     4703945             4183   \n",
       "5         2000     1999-10-01   2000-09-30     4736858             3785   \n",
       "6         2001     2000-10-01   2001-09-30     4733613             3774   \n",
       "7         2002     2001-10-01   2002-09-30     4734891             3722   \n",
       "8         2003     2002-10-01   2003-09-30     4737424             3344   \n",
       "9         2004     2003-10-01   2004-09-30     4748570             3742   \n",
       "10        2005     2004-10-01   2005-09-30     4731884             3384   \n",
       "11        2006     2005-10-01   2006-09-30     4724236             4211   \n",
       "12        2007     2006-10-01   2007-09-30     4693207             5182   \n",
       "13        2008     2007-10-01   2008-09-30     4702545             4516   \n",
       "14        2009     2008-10-01   2009-09-30     4709848             3422   \n",
       "15        2010     2009-10-01   2010-09-30     4720797             2905   \n",
       "16        2011     2010-10-01   2011-09-30     4715943             2745   \n",
       "17        2012     2011-10-01   2012-09-30     4710806             3100   \n",
       "18        2013     2012-10-01   2013-09-30     4720365             2823   \n",
       "19        2014     2013-10-01   2014-09-30     4736373             2997   \n",
       "20        2015     2014-10-01   2015-09-30     4738623             2530   \n",
       "21        2016     2015-10-01   2016-09-30     4748416             2789   \n",
       "22        2017     2016-10-01   2017-09-30     4736351             2689   \n",
       "23        2018     2017-10-01   2018-09-30     4733293             2969   \n",
       "24        2019     2018-10-01   2019-09-30     4734565             1912   \n",
       "25        2020     2019-10-01   2020-09-30     4732622             2338   \n",
       "\n",
       "    Fire Percentage (%)  \n",
       "0              0.070823  \n",
       "1              0.096885  \n",
       "2              0.084326  \n",
       "3              0.060638  \n",
       "4              0.088925  \n",
       "5              0.079905  \n",
       "6              0.079728  \n",
       "7              0.078608  \n",
       "8              0.070587  \n",
       "9              0.078803  \n",
       "10             0.071515  \n",
       "11             0.089136  \n",
       "12             0.110415  \n",
       "13             0.096033  \n",
       "14             0.072656  \n",
       "15             0.061536  \n",
       "16             0.058207  \n",
       "17             0.065806  \n",
       "18             0.059805  \n",
       "19             0.063276  \n",
       "20             0.053391  \n",
       "21             0.058735  \n",
       "22             0.056774  \n",
       "23             0.062726  \n",
       "24             0.040384  \n",
       "25             0.049402  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing Water Years: 100%|██████████| 26/26 [05:07<00:00, 11.85s/it]\n"
     ]
    }
   ],
   "source": [
    "input_path = '../../Clean_Data/Model_Data/Evaluation/Features_w_Label/Extended_Data_Water_Year'\n",
    "save_path = '../../Clean_Data/Model_Data/Evaluation/Features_w_Label/Extended_Data_Water_Year_no_riparian'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "for year in tqdm(range(1995, 2021), desc=\"Summarizing Water Years\"):\n",
    "\n",
    "    fire_label_path = os.path.join(input_path, f'{year}_features_w_label.parquet')\n",
    "    mod_data = pd.read_parquet(fire_label_path)\n",
    "    \n",
    "    # remove veg containing 'Riparian'\n",
    "    mod_data = mod_data[~mod_data['veg'].str.contains('Riparian')]\n",
    "    # save\n",
    "    mod_data.to_parquet(f\"{save_path}/{year}_features_w_label.parquet\")\n",
    "\n",
    "    # free up memory\n",
    "    del mod_data\n",
    "    # gc\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
