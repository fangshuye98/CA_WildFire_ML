{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove population density\n",
    "- Remove Veg\n",
    "\n",
    "https://github.com/fangshuye98/CA_WildFire_ML/issues/11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Force garbage collection\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_recall_curve,auc\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas version\n",
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "# check python version and all packages version\n",
    "def check_python_version():\n",
    "    import sys\n",
    "    print(\"Python version\")\n",
    "    print (sys.version)\n",
    "    print(\"Pandas version\")\n",
    "    print(pd.__version__)\n",
    "\n",
    "check_python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, features, label_col):\n",
    "    X_train = train_data[features]\n",
    "    y_train = train_data[label_col]\n",
    "    # train the model\n",
    "    model = xgb.XGBClassifier(eval_metric='logloss', tree_method='hist')\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# define function to calculate precision and recall based on a threshold\n",
    "def calculate_precision_recall(y_true, y_pred_proba, threshold, print_output=False):\n",
    "    y_pred = (y_pred_proba > threshold).astype(int)\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "    precision = confusion[1, 1] / (confusion[1, 1] + confusion[0, 1])\n",
    "    recall = confusion[1, 1] / (confusion[1, 1] + confusion[1, 0])\n",
    "    # F1 score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    if print_output:\n",
    "        print(f'Threshold: {threshold:.2f}')\n",
    "        print(f'Precision: {precision * 100:.2f}%')\n",
    "        print(f'Recall: {recall * 100:.2f}%')\n",
    "        print(\"Confusion Matrix\")\n",
    "        print(pd.DataFrame(confusion, index=['True Neg', 'True Pos'], columns=['Pred Neg', 'Pred Pos']))\n",
    "    # get TP, TN, FP, FN\n",
    "    TP = confusion[1, 1]\n",
    "    TN = confusion[0, 0]\n",
    "    FP = confusion[0, 1]\n",
    "    FN = confusion[1, 0]\n",
    "    return TP, TN, FP, FN, precision, recall, f1\n",
    "\n",
    "def evaluate_model(model, test_data, features, label_col):\n",
    "    X_test = test_data[features]\n",
    "    y_test = test_data[label_col]\n",
    "    # predict the probability of fire\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    # calculate the roc_auc_score\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    # print roc_auc in a sentence\n",
    "    # print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "    # Calculate precision and recall values\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "    # Calculate the area under the precision-recall curve\n",
    "    auc_pr = auc(recall, precision)\n",
    "    # print(f\"Area Under Precision-Recall Curve (AUC-PR): {auc_pr:.2f}\")\n",
    "    # calculate precision and recall at thresholds 0.5\n",
    "    TP, TN, FP, FN, precision5, recall5, f15 = calculate_precision_recall(y_test, y_pred, 0.5)\n",
    "    return roc_auc, auc_pr, TP, TN, FP, FN, precision5, recall5, f15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Water Years 2007 using training data: 2000-10-01 00:00:00 ~ 2006-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "def get_water_year_range(target_year, num_years=6):\n",
    "    min_year = target_year - num_years - 1\n",
    "    min_day = f\"{min_year}-10-01 00:00:00\"\n",
    "    max_day = f\"{target_year-1}-09-30 00:00:00\"\n",
    "    return min_day, max_day\n",
    "\n",
    "# Example: Get range for Water Year 2007\n",
    "target_year = 2007\n",
    "min_day, max_day = get_water_year_range(target_year)\n",
    "\n",
    "print(f\"Predict Water Years {target_year} using training data: {min_day} ~ {max_day}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = \"Extended_Data_Water_Year_no_riparian_remove_veg\"\n",
    "input_data_version = \"Extended_Data_Water_Year_no_riparian\"\n",
    "\n",
    "initial_features = ['dead_fuel_moisture_1000hr',\n",
    "       'dead_fuel_moisture_100hr', \n",
    "       'max_air_temperature', 'max_relative_humidity', \n",
    "       'min_air_temperature', 'min_relative_humidity', 'precipitation_amount',\n",
    "       'specific_humidity', 'surface_downwelling_shortwave_flux_in_air',\n",
    "       #'wind_from_direction', \n",
    "       'wind_speed', 'wind_direction_category', 'SWE',\n",
    "       #'population_density',\n",
    "       'LAI', \n",
    "       #'pdsi', \n",
    "       #'IS_FIRE', \n",
    "       #'min_FIRE_SIZE', 'max_FIRE_SIZE', 'Year','fire_attribute', \n",
    "       #'veg', \n",
    "       #'veg_group',\n",
    "       #'slope_avg', \n",
    "       'slope_max',\n",
    "       'road_density_km_km2',\n",
    "       'line_density_km_per_cell' \n",
    "       ]\n",
    "cat_columns = ['wind_direction_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing years: 100%|██████████| 20/20 [10:21<00:00, 31.10s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "log_messages = []\n",
    "log_messages.append(\"Model Version: Remove veg feature and remove riparian area and remove population density\")\n",
    "# add log to record the current time\n",
    "log_messages.append(f\"Start time: {pd.Timestamp.now()}\")\n",
    "# Define the range of years to predict\n",
    "years = range(2001, 2021)\n",
    "\n",
    "\n",
    "# Plot\n",
    "model_path = f'../../Model/{model_version}'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "save_predictions_path = f'../../Clean_Data/Model_Data/Evaluation/Features_w_Label_w_pred/{model_version}/parquet'\n",
    "if not os.path.exists(save_predictions_path):\n",
    "    os.makedirs(save_predictions_path)  \n",
    "\n",
    "# surpass the warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "mod_Human = pd.read_parquet(f'../../Clean_Data/Model_Data/Downsample/Features_w_Label/features_w_label_downsample_1994_2020_no_riparian.parquet')\n",
    "\n",
    "input_path = f'../../Clean_Data/Model_Data/Evaluation/Features_w_Label/{input_data_version}'\n",
    "# Iterate over the years with a progress bar\n",
    "for year in tqdm(years, desc=\"Processing years\"):\n",
    "    log_messages.append(\"-\" * 50)\n",
    "    # log current water year\n",
    "    log_messages.append(f\"Processing Water Year: {year}\")\n",
    "    # read eval data, prev-year Oct - current year Sep\n",
    "    Eval_Human = pd.read_parquet(f'{input_path}/{year}_features_w_label.parquet')\n",
    "\n",
    "    # get water year range\n",
    "    min_day, max_day = get_water_year_range(year)\n",
    "    # filter the training data\n",
    "    train_data = mod_Human[(mod_Human['day'] >= min_day) & (mod_Human['day'] <= max_day)]\n",
    "    # use log message to show the min and max of day from mod_Human\n",
    "    log_messages.append(f\"Training Data Day min: {train_data['day'].min()}, max: {train_data['day'].max()}\")\n",
    "    #mod_Human = mod_Human[features_to_keep]\n",
    "    #Eval_Human = Eval_Human[features_to_keep]\n",
    "\n",
    "    \n",
    "    # one hot encoding\n",
    "    train_data = pd.get_dummies(train_data, columns=cat_columns)\n",
    "    Eval_Human = pd.get_dummies(Eval_Human, columns=cat_columns)\n",
    "\n",
    "    # extract column names starting with 'wind_direction_category_' and 'veg_'\n",
    "    wind_direction_category_cols = [col for col in train_data.columns if col.startswith('wind_direction_category_')]\n",
    "    # veg_cols = [col for col in train_data.columns if col.startswith('veg_group_') and col != 'veg_type_details']\n",
    "\n",
    "    features = initial_features + wind_direction_category_cols\n",
    "    # drop cat_columns from features\n",
    "    features = [col for col in features if col not in cat_columns]\n",
    "\n",
    "    label_col = 'IS_FIRE'\n",
    "    model = train_model(train_data, features, label_col)\n",
    "    # save model to a pickle file\n",
    "    with open(f'{model_path}/predict_{year}_6yr_model.pkl', 'wb') as f:\n",
    "         pickle.dump(model, f)\n",
    "    # save model to ../../Model/predict_year\n",
    "    # model.save_model(f'../../Model/predict_{year}_6yr_model.json')\n",
    "    # evaluate the model\n",
    "    roc_auc, auc_pr, TP, TN, FP, FN, precision5, recall5, f15 = evaluate_model(model, Eval_Human, features, label_col)\n",
    "    # append the results to the list\n",
    "    results.append([year, roc_auc, auc_pr, TP, TN, FP, FN, precision5, recall5, f15])\n",
    "\n",
    "    # add predictions to Eval_Human\n",
    "    Eval_Human['predictions'] = model.predict_proba(Eval_Human[features])[:, 1]\n",
    "    # save the predictions to a parquet file\n",
    "    Eval_Human.to_parquet(f'{save_predictions_path}/{year}_predictions.parquet', index=False)\n",
    "\n",
    "    # clean up the dataframes\n",
    "    del train_data\n",
    "    del Eval_Human\n",
    "\n",
    "    # clean the cache\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the log messages to a log file\n",
    "with open('../../Logs/Clean_Extended_Data/model_training_6_years_no_riparian_no_pop_no_veg.txt', 'w') as log_file:\n",
    "    log_file.write('\\n'.join(log_messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign column names to the results\n",
    "results_pd = pd.DataFrame(results, columns=['Year', 'ROC_AUC', 'AUC_PR', 'TP', 'TN', 'FP', 'FN', 'Precision_0.5', 'Recall_0.5', 'F1_0.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>AUC_PR</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Precision_0.5</th>\n",
       "      <th>Recall_0.5</th>\n",
       "      <th>F1_0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.850023</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>91</td>\n",
       "      <td>4628353</td>\n",
       "      <td>676</td>\n",
       "      <td>3585</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.024755</td>\n",
       "      <td>0.040963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>0.844716</td>\n",
       "      <td>0.026346</td>\n",
       "      <td>110</td>\n",
       "      <td>4629196</td>\n",
       "      <td>701</td>\n",
       "      <td>3526</td>\n",
       "      <td>0.135635</td>\n",
       "      <td>0.030253</td>\n",
       "      <td>0.049472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>0.857619</td>\n",
       "      <td>0.020102</td>\n",
       "      <td>77</td>\n",
       "      <td>4632409</td>\n",
       "      <td>396</td>\n",
       "      <td>3178</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.023656</td>\n",
       "      <td>0.041309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>0.848871</td>\n",
       "      <td>0.019810</td>\n",
       "      <td>77</td>\n",
       "      <td>4642923</td>\n",
       "      <td>420</td>\n",
       "      <td>3556</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>0.021195</td>\n",
       "      <td>0.037288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>0.878957</td>\n",
       "      <td>0.023331</td>\n",
       "      <td>72</td>\n",
       "      <td>4629390</td>\n",
       "      <td>386</td>\n",
       "      <td>3060</td>\n",
       "      <td>0.157205</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.040111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2006</td>\n",
       "      <td>0.866318</td>\n",
       "      <td>0.024756</td>\n",
       "      <td>88</td>\n",
       "      <td>4622544</td>\n",
       "      <td>280</td>\n",
       "      <td>3775</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.022780</td>\n",
       "      <td>0.041598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007</td>\n",
       "      <td>0.853835</td>\n",
       "      <td>0.029394</td>\n",
       "      <td>108</td>\n",
       "      <td>4590943</td>\n",
       "      <td>268</td>\n",
       "      <td>4773</td>\n",
       "      <td>0.287234</td>\n",
       "      <td>0.022127</td>\n",
       "      <td>0.041088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008</td>\n",
       "      <td>0.842239</td>\n",
       "      <td>0.021577</td>\n",
       "      <td>118</td>\n",
       "      <td>4600368</td>\n",
       "      <td>560</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.174041</td>\n",
       "      <td>0.028002</td>\n",
       "      <td>0.048242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.861342</td>\n",
       "      <td>0.020591</td>\n",
       "      <td>93</td>\n",
       "      <td>4608362</td>\n",
       "      <td>618</td>\n",
       "      <td>3070</td>\n",
       "      <td>0.130802</td>\n",
       "      <td>0.029402</td>\n",
       "      <td>0.048012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010</td>\n",
       "      <td>0.868664</td>\n",
       "      <td>0.012996</td>\n",
       "      <td>48</td>\n",
       "      <td>4619561</td>\n",
       "      <td>497</td>\n",
       "      <td>2584</td>\n",
       "      <td>0.088073</td>\n",
       "      <td>0.018237</td>\n",
       "      <td>0.030217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2011</td>\n",
       "      <td>0.874724</td>\n",
       "      <td>0.027449</td>\n",
       "      <td>92</td>\n",
       "      <td>4614579</td>\n",
       "      <td>427</td>\n",
       "      <td>2416</td>\n",
       "      <td>0.177264</td>\n",
       "      <td>0.036683</td>\n",
       "      <td>0.060786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012</td>\n",
       "      <td>0.827640</td>\n",
       "      <td>0.017826</td>\n",
       "      <td>97</td>\n",
       "      <td>4606932</td>\n",
       "      <td>994</td>\n",
       "      <td>2886</td>\n",
       "      <td>0.088909</td>\n",
       "      <td>0.032518</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013</td>\n",
       "      <td>0.841311</td>\n",
       "      <td>0.022729</td>\n",
       "      <td>97</td>\n",
       "      <td>4616456</td>\n",
       "      <td>692</td>\n",
       "      <td>2627</td>\n",
       "      <td>0.122940</td>\n",
       "      <td>0.035609</td>\n",
       "      <td>0.055223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014</td>\n",
       "      <td>0.807355</td>\n",
       "      <td>0.021764</td>\n",
       "      <td>97</td>\n",
       "      <td>4631900</td>\n",
       "      <td>508</td>\n",
       "      <td>2801</td>\n",
       "      <td>0.160331</td>\n",
       "      <td>0.033471</td>\n",
       "      <td>0.055381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015</td>\n",
       "      <td>0.824982</td>\n",
       "      <td>0.021995</td>\n",
       "      <td>86</td>\n",
       "      <td>4634810</td>\n",
       "      <td>274</td>\n",
       "      <td>2361</td>\n",
       "      <td>0.238889</td>\n",
       "      <td>0.035145</td>\n",
       "      <td>0.061275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.848359</td>\n",
       "      <td>0.037464</td>\n",
       "      <td>118</td>\n",
       "      <td>4645042</td>\n",
       "      <td>217</td>\n",
       "      <td>2541</td>\n",
       "      <td>0.352239</td>\n",
       "      <td>0.044378</td>\n",
       "      <td>0.078824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.870819</td>\n",
       "      <td>0.015315</td>\n",
       "      <td>53</td>\n",
       "      <td>4633258</td>\n",
       "      <td>254</td>\n",
       "      <td>2516</td>\n",
       "      <td>0.172638</td>\n",
       "      <td>0.020631</td>\n",
       "      <td>0.036857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.838317</td>\n",
       "      <td>0.015281</td>\n",
       "      <td>63</td>\n",
       "      <td>4631515</td>\n",
       "      <td>303</td>\n",
       "      <td>2695</td>\n",
       "      <td>0.172131</td>\n",
       "      <td>0.022843</td>\n",
       "      <td>0.040333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.837892</td>\n",
       "      <td>0.008596</td>\n",
       "      <td>36</td>\n",
       "      <td>4633904</td>\n",
       "      <td>279</td>\n",
       "      <td>1684</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.020930</td>\n",
       "      <td>0.035381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.846613</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>35</td>\n",
       "      <td>4631064</td>\n",
       "      <td>317</td>\n",
       "      <td>2124</td>\n",
       "      <td>0.099432</td>\n",
       "      <td>0.016211</td>\n",
       "      <td>0.027877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year   ROC_AUC    AUC_PR   TP       TN   FP    FN  Precision_0.5  \\\n",
       "0   2001  0.850023  0.022484   91  4628353  676  3585       0.118644   \n",
       "1   2002  0.844716  0.026346  110  4629196  701  3526       0.135635   \n",
       "2   2003  0.857619  0.020102   77  4632409  396  3178       0.162791   \n",
       "3   2004  0.848871  0.019810   77  4642923  420  3556       0.154930   \n",
       "4   2005  0.878957  0.023331   72  4629390  386  3060       0.157205   \n",
       "5   2006  0.866318  0.024756   88  4622544  280  3775       0.239130   \n",
       "6   2007  0.853835  0.029394  108  4590943  268  4773       0.287234   \n",
       "7   2008  0.842239  0.021577  118  4600368  560  4096       0.174041   \n",
       "8   2009  0.861342  0.020591   93  4608362  618  3070       0.130802   \n",
       "9   2010  0.868664  0.012996   48  4619561  497  2584       0.088073   \n",
       "10  2011  0.874724  0.027449   92  4614579  427  2416       0.177264   \n",
       "11  2012  0.827640  0.017826   97  4606932  994  2886       0.088909   \n",
       "12  2013  0.841311  0.022729   97  4616456  692  2627       0.122940   \n",
       "13  2014  0.807355  0.021764   97  4631900  508  2801       0.160331   \n",
       "14  2015  0.824982  0.021995   86  4634810  274  2361       0.238889   \n",
       "15  2016  0.848359  0.037464  118  4645042  217  2541       0.352239   \n",
       "16  2017  0.870819  0.015315   53  4633258  254  2516       0.172638   \n",
       "17  2018  0.838317  0.015281   63  4631515  303  2695       0.172131   \n",
       "18  2019  0.837892  0.008596   36  4633904  279  1684       0.114286   \n",
       "19  2020  0.846613  0.011560   35  4631064  317  2124       0.099432   \n",
       "\n",
       "    Recall_0.5    F1_0.5  \n",
       "0     0.024755  0.040963  \n",
       "1     0.030253  0.049472  \n",
       "2     0.023656  0.041309  \n",
       "3     0.021195  0.037288  \n",
       "4     0.022989  0.040111  \n",
       "5     0.022780  0.041598  \n",
       "6     0.022127  0.041088  \n",
       "7     0.028002  0.048242  \n",
       "8     0.029402  0.048012  \n",
       "9     0.018237  0.030217  \n",
       "10    0.036683  0.060786  \n",
       "11    0.032518  0.047619  \n",
       "12    0.035609  0.055223  \n",
       "13    0.033471  0.055381  \n",
       "14    0.035145  0.061275  \n",
       "15    0.044378  0.078824  \n",
       "16    0.020631  0.036857  \n",
       "17    0.022843  0.040333  \n",
       "18    0.020930  0.035381  \n",
       "19    0.016211  0.027877  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del all variables to free up memory\n",
    "del mod_Human\n",
    "del results\n",
    "del results_pd\n",
    "# clean the cache\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all data\n",
    "for name in dir():\n",
    "    if not name.startswith('_'):\n",
    "        del globals()[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = \"Extended_Data_Water_Year_no_riparian_remove_veg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing years:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing years: 100%|██████████| 20/20 [58:40<00:00, 176.04s/it]\n"
     ]
    }
   ],
   "source": [
    "# save all parquet to csv\n",
    "years = range(2001, 2021)\n",
    "\n",
    "input_path = f'../../Clean_Data/Model_Data/Evaluation/Features_w_Label_w_pred/{model_version}/parquet'\n",
    "output_path = f'../../Clean_Data/Model_Data/Evaluation/Features_w_Label_w_pred/{model_version}/csv'\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "for year in tqdm(years, desc=\"Processing years\"):\n",
    "    # read the parquet file\n",
    "    df = pd.read_parquet(f'{input_path}/{year}_predictions.parquet')  \n",
    "    # write to csv\n",
    "    df.to_csv(f'{output_path}/{year}_predictions.csv', index=False)\n",
    "\n",
    "    # clean up the dataframes\n",
    "    del df\n",
    "    # clean the cache\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
