{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove population density\n",
    "\n",
    "https://github.com/fangshuye98/CA_WildFire_ML/issues/11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Force garbage collection\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_recall_curve,auc\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas version\n",
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "# check python version and all packages version\n",
    "def check_python_version():\n",
    "    import sys\n",
    "    print(\"Python version\")\n",
    "    print (sys.version)\n",
    "    print(\"Pandas version\")\n",
    "    print(pd.__version__)\n",
    "\n",
    "check_python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_features = ['dead_fuel_moisture_1000hr',\n",
    "       'dead_fuel_moisture_100hr', \n",
    "       'max_air_temperature', 'max_relative_humidity', \n",
    "       'min_air_temperature', 'min_relative_humidity', 'precipitation_amount',\n",
    "       'specific_humidity', 'surface_downwelling_shortwave_flux_in_air',\n",
    "       #'wind_from_direction', \n",
    "       'wind_speed', 'wind_direction_category', 'SWE',\n",
    "       #'population_density',\n",
    "       'LAI', \n",
    "       #'pdsi', \n",
    "       #'IS_FIRE', \n",
    "       #'min_FIRE_SIZE', 'max_FIRE_SIZE', 'Year','fire_attribute', \n",
    "       #'veg', \n",
    "       'veg_group',\n",
    "       #'slope_avg', \n",
    "       'slope_max',\n",
    "       'road_density_km_km2',\n",
    "       'line_density_km_per_cell' \n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, features, label_col):\n",
    "    X_train = train_data[features]\n",
    "    y_train = train_data[label_col]\n",
    "    # train the model\n",
    "    model = xgb.XGBClassifier(eval_metric='logloss', tree_method='hist')\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# define function to calculate precision and recall based on a threshold\n",
    "def calculate_precision_recall(y_true, y_pred_proba, threshold, print_output=False):\n",
    "    y_pred = (y_pred_proba > threshold).astype(int)\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "    precision = confusion[1, 1] / (confusion[1, 1] + confusion[0, 1])\n",
    "    recall = confusion[1, 1] / (confusion[1, 1] + confusion[1, 0])\n",
    "    # F1 score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    if print_output:\n",
    "        print(f'Threshold: {threshold:.2f}')\n",
    "        print(f'Precision: {precision * 100:.2f}%')\n",
    "        print(f'Recall: {recall * 100:.2f}%')\n",
    "        print(\"Confusion Matrix\")\n",
    "        print(pd.DataFrame(confusion, index=['True Neg', 'True Pos'], columns=['Pred Neg', 'Pred Pos']))\n",
    "    # get TP, TN, FP, FN\n",
    "    TP = confusion[1, 1]\n",
    "    TN = confusion[0, 0]\n",
    "    FP = confusion[0, 1]\n",
    "    FN = confusion[1, 0]\n",
    "    return TP, TN, FP, FN, precision, recall, f1\n",
    "\n",
    "def evaluate_model(model, test_data, features, label_col):\n",
    "    X_test = test_data[features]\n",
    "    y_test = test_data[label_col]\n",
    "    # predict the probability of fire\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    # calculate the roc_auc_score\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    # print roc_auc in a sentence\n",
    "    # print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "    # Calculate precision and recall values\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "    # Calculate the area under the precision-recall curve\n",
    "    auc_pr = auc(recall, precision)\n",
    "    # print(f\"Area Under Precision-Recall Curve (AUC-PR): {auc_pr:.2f}\")\n",
    "    # calculate precision and recall at thresholds 0.5\n",
    "    TP, TN, FP, FN, precision5, recall5, f15 = calculate_precision_recall(y_test, y_pred, 0.5)\n",
    "    return roc_auc, auc_pr, TP, TN, FP, FN, precision5, recall5, f15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Water Years 2007 using training data: 2000-10-01 00:00:00 ~ 2006-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "def get_water_year_range(target_year, num_years=6):\n",
    "    min_year = target_year - num_years - 1\n",
    "    min_day = f\"{min_year}-10-01 00:00:00\"\n",
    "    max_day = f\"{target_year-1}-09-30 00:00:00\"\n",
    "    return min_day, max_day\n",
    "\n",
    "# Example: Get range for Water Year 2007\n",
    "target_year = 2007\n",
    "min_day, max_day = get_water_year_range(target_year)\n",
    "\n",
    "print(f\"Predict Water Years {target_year} using training data: {min_day} ~ {max_day}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = \"Extended_Data_Water_Year_no_riparian_group_veg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing years: 100%|██████████| 20/20 [07:51<00:00, 23.59s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "log_messages = []\n",
    "log_messages.append(\"Model Version: Regrouping veg and remove riparian and remove population density\")\n",
    "# add log to record the current time\n",
    "log_messages.append(f\"Start time: {pd.Timestamp.now()}\")\n",
    "# Define the range of years to predict\n",
    "years = range(2001, 2021)\n",
    "\n",
    "\n",
    "# Plot\n",
    "model_path = f'../../Model/{model_version}'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "save_predictions_path = f'../../Clean_Data/Model_Data/Evaluation/Features_w_Label_w_pred/{model_version}/parquet'\n",
    "if not os.path.exists(save_predictions_path):\n",
    "    os.makedirs(save_predictions_path)  \n",
    "\n",
    "# surpass the warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "mod_Human = pd.read_parquet(f'../../Clean_Data/Model_Data/Downsample/Features_w_Label/features_w_label_downsample_1994_2020_no_riparian_group_veg.parquet')\n",
    "\n",
    "input_path = f'../../Clean_Data/Model_Data/Evaluation/Features_w_Label/{model_version}'\n",
    "# Iterate over the years with a progress bar\n",
    "for year in tqdm(years, desc=\"Processing years\"):\n",
    "    log_messages.append(\"-\" * 50)\n",
    "    # log current water year\n",
    "    log_messages.append(f\"Processing Water Year: {year}\")\n",
    "    # read eval data, prev-year Oct - current year Sep\n",
    "    Eval_Human = pd.read_parquet(f'{input_path}/{year}_features_w_label.parquet')\n",
    "\n",
    "    # get water year range\n",
    "    min_day, max_day = get_water_year_range(year)\n",
    "    # filter the training data\n",
    "    train_data = mod_Human[(mod_Human['day'] >= min_day) & (mod_Human['day'] <= max_day)]\n",
    "    # use log message to show the min and max of day from mod_Human\n",
    "    log_messages.append(f\"Training Data Day min: {train_data['day'].min()}, max: {train_data['day'].max()}\")\n",
    "    #mod_Human = mod_Human[features_to_keep]\n",
    "    #Eval_Human = Eval_Human[features_to_keep]\n",
    "\n",
    "    cat_columns = ['wind_direction_category','veg_group']\n",
    "\n",
    "    # one hot encoding\n",
    "    train_data = pd.get_dummies(train_data, columns=cat_columns)\n",
    "    Eval_Human = pd.get_dummies(Eval_Human, columns=cat_columns)\n",
    "\n",
    "    # extract column names starting with 'wind_direction_category_' and 'veg_'\n",
    "    wind_direction_category_cols = [col for col in train_data.columns if col.startswith('wind_direction_category_')]\n",
    "    veg_cols = [col for col in train_data.columns if col.startswith('veg_group_') and col != 'veg_type_details']\n",
    "\n",
    "    features = initial_features + wind_direction_category_cols + veg_cols\n",
    "    # drop cat_columns from features\n",
    "    features = [col for col in features if col not in cat_columns]\n",
    "\n",
    "    label_col = 'IS_FIRE'\n",
    "    model = train_model(train_data, features, label_col)\n",
    "    # save model to a pickle file\n",
    "    with open(f'{model_path}/predict_{year}_6yr_model.pkl', 'wb') as f:\n",
    "         pickle.dump(model, f)\n",
    "    # save model to ../../Model/predict_year\n",
    "    # model.save_model(f'../../Model/predict_{year}_6yr_model.json')\n",
    "    # evaluate the model\n",
    "    roc_auc, auc_pr, TP, TN, FP, FN, precision5, recall5, f15 = evaluate_model(model, Eval_Human, features, label_col)\n",
    "    # append the results to the list\n",
    "    results.append([year, roc_auc, auc_pr, TP, TN, FP, FN, precision5, recall5, f15])\n",
    "\n",
    "    # add predictions to Eval_Human\n",
    "    Eval_Human['predictions'] = model.predict_proba(Eval_Human[features])[:, 1]\n",
    "    # save the predictions to a parquet file\n",
    "    Eval_Human.to_parquet(f'{save_predictions_path}/{year}_predictions.parquet', index=False)\n",
    "\n",
    "    # clean up the dataframes\n",
    "    del train_data\n",
    "    del Eval_Human\n",
    "\n",
    "    # clean the cache\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the log messages to a log file\n",
    "with open('../../Logs/Clean_Extended_Data/model_training_6_years_no_riparian_no_pop_group_veg.txt', 'w') as log_file:\n",
    "    log_file.write('\\n'.join(log_messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign column names to the results\n",
    "results_pd = pd.DataFrame(results, columns=['Year', 'ROC_AUC', 'AUC_PR', 'TP', 'TN', 'FP', 'FN', 'Precision_0.5', 'Recall_0.5', 'F1_0.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>AUC_PR</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Precision_0.5</th>\n",
       "      <th>Recall_0.5</th>\n",
       "      <th>F1_0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.855101</td>\n",
       "      <td>0.020185</td>\n",
       "      <td>103</td>\n",
       "      <td>4627887</td>\n",
       "      <td>1142</td>\n",
       "      <td>3573</td>\n",
       "      <td>0.082731</td>\n",
       "      <td>0.028020</td>\n",
       "      <td>0.041861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>0.849620</td>\n",
       "      <td>0.024006</td>\n",
       "      <td>100</td>\n",
       "      <td>4629129</td>\n",
       "      <td>768</td>\n",
       "      <td>3536</td>\n",
       "      <td>0.115207</td>\n",
       "      <td>0.027503</td>\n",
       "      <td>0.044405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>0.860118</td>\n",
       "      <td>0.021816</td>\n",
       "      <td>79</td>\n",
       "      <td>4632315</td>\n",
       "      <td>490</td>\n",
       "      <td>3176</td>\n",
       "      <td>0.138840</td>\n",
       "      <td>0.024270</td>\n",
       "      <td>0.041318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>0.850818</td>\n",
       "      <td>0.019338</td>\n",
       "      <td>89</td>\n",
       "      <td>4642791</td>\n",
       "      <td>552</td>\n",
       "      <td>3544</td>\n",
       "      <td>0.138846</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.041647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>0.879241</td>\n",
       "      <td>0.023520</td>\n",
       "      <td>74</td>\n",
       "      <td>4629490</td>\n",
       "      <td>286</td>\n",
       "      <td>3058</td>\n",
       "      <td>0.205556</td>\n",
       "      <td>0.023627</td>\n",
       "      <td>0.042383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2006</td>\n",
       "      <td>0.870346</td>\n",
       "      <td>0.024821</td>\n",
       "      <td>86</td>\n",
       "      <td>4622516</td>\n",
       "      <td>308</td>\n",
       "      <td>3777</td>\n",
       "      <td>0.218274</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0.040404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007</td>\n",
       "      <td>0.854619</td>\n",
       "      <td>0.030880</td>\n",
       "      <td>102</td>\n",
       "      <td>4590916</td>\n",
       "      <td>295</td>\n",
       "      <td>4779</td>\n",
       "      <td>0.256927</td>\n",
       "      <td>0.020897</td>\n",
       "      <td>0.038651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008</td>\n",
       "      <td>0.843505</td>\n",
       "      <td>0.022215</td>\n",
       "      <td>107</td>\n",
       "      <td>4600419</td>\n",
       "      <td>509</td>\n",
       "      <td>4107</td>\n",
       "      <td>0.173701</td>\n",
       "      <td>0.025392</td>\n",
       "      <td>0.044306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.865310</td>\n",
       "      <td>0.021311</td>\n",
       "      <td>94</td>\n",
       "      <td>4608318</td>\n",
       "      <td>662</td>\n",
       "      <td>3069</td>\n",
       "      <td>0.124339</td>\n",
       "      <td>0.029719</td>\n",
       "      <td>0.047971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010</td>\n",
       "      <td>0.871431</td>\n",
       "      <td>0.013665</td>\n",
       "      <td>51</td>\n",
       "      <td>4619517</td>\n",
       "      <td>541</td>\n",
       "      <td>2581</td>\n",
       "      <td>0.086149</td>\n",
       "      <td>0.019377</td>\n",
       "      <td>0.031638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2011</td>\n",
       "      <td>0.877867</td>\n",
       "      <td>0.024669</td>\n",
       "      <td>92</td>\n",
       "      <td>4614535</td>\n",
       "      <td>471</td>\n",
       "      <td>2416</td>\n",
       "      <td>0.163410</td>\n",
       "      <td>0.036683</td>\n",
       "      <td>0.059915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012</td>\n",
       "      <td>0.831720</td>\n",
       "      <td>0.018769</td>\n",
       "      <td>87</td>\n",
       "      <td>4606991</td>\n",
       "      <td>935</td>\n",
       "      <td>2896</td>\n",
       "      <td>0.085127</td>\n",
       "      <td>0.029165</td>\n",
       "      <td>0.043446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013</td>\n",
       "      <td>0.846207</td>\n",
       "      <td>0.023065</td>\n",
       "      <td>98</td>\n",
       "      <td>4616516</td>\n",
       "      <td>632</td>\n",
       "      <td>2626</td>\n",
       "      <td>0.134247</td>\n",
       "      <td>0.035977</td>\n",
       "      <td>0.056746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014</td>\n",
       "      <td>0.816596</td>\n",
       "      <td>0.022084</td>\n",
       "      <td>92</td>\n",
       "      <td>4631845</td>\n",
       "      <td>563</td>\n",
       "      <td>2806</td>\n",
       "      <td>0.140458</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.051787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015</td>\n",
       "      <td>0.831484</td>\n",
       "      <td>0.022584</td>\n",
       "      <td>90</td>\n",
       "      <td>4634783</td>\n",
       "      <td>301</td>\n",
       "      <td>2357</td>\n",
       "      <td>0.230179</td>\n",
       "      <td>0.036780</td>\n",
       "      <td>0.063425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.849591</td>\n",
       "      <td>0.035230</td>\n",
       "      <td>118</td>\n",
       "      <td>4644970</td>\n",
       "      <td>289</td>\n",
       "      <td>2541</td>\n",
       "      <td>0.289926</td>\n",
       "      <td>0.044378</td>\n",
       "      <td>0.076973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.874518</td>\n",
       "      <td>0.015564</td>\n",
       "      <td>53</td>\n",
       "      <td>4633152</td>\n",
       "      <td>360</td>\n",
       "      <td>2516</td>\n",
       "      <td>0.128329</td>\n",
       "      <td>0.020631</td>\n",
       "      <td>0.035547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.843105</td>\n",
       "      <td>0.017712</td>\n",
       "      <td>65</td>\n",
       "      <td>4631537</td>\n",
       "      <td>281</td>\n",
       "      <td>2693</td>\n",
       "      <td>0.187861</td>\n",
       "      <td>0.023568</td>\n",
       "      <td>0.041881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.840833</td>\n",
       "      <td>0.010959</td>\n",
       "      <td>35</td>\n",
       "      <td>4633859</td>\n",
       "      <td>324</td>\n",
       "      <td>1685</td>\n",
       "      <td>0.097493</td>\n",
       "      <td>0.020349</td>\n",
       "      <td>0.033670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.847943</td>\n",
       "      <td>0.011809</td>\n",
       "      <td>43</td>\n",
       "      <td>4631100</td>\n",
       "      <td>281</td>\n",
       "      <td>2116</td>\n",
       "      <td>0.132716</td>\n",
       "      <td>0.019917</td>\n",
       "      <td>0.034636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year   ROC_AUC    AUC_PR   TP       TN    FP    FN  Precision_0.5  \\\n",
       "0   2001  0.855101  0.020185  103  4627887  1142  3573       0.082731   \n",
       "1   2002  0.849620  0.024006  100  4629129   768  3536       0.115207   \n",
       "2   2003  0.860118  0.021816   79  4632315   490  3176       0.138840   \n",
       "3   2004  0.850818  0.019338   89  4642791   552  3544       0.138846   \n",
       "4   2005  0.879241  0.023520   74  4629490   286  3058       0.205556   \n",
       "5   2006  0.870346  0.024821   86  4622516   308  3777       0.218274   \n",
       "6   2007  0.854619  0.030880  102  4590916   295  4779       0.256927   \n",
       "7   2008  0.843505  0.022215  107  4600419   509  4107       0.173701   \n",
       "8   2009  0.865310  0.021311   94  4608318   662  3069       0.124339   \n",
       "9   2010  0.871431  0.013665   51  4619517   541  2581       0.086149   \n",
       "10  2011  0.877867  0.024669   92  4614535   471  2416       0.163410   \n",
       "11  2012  0.831720  0.018769   87  4606991   935  2896       0.085127   \n",
       "12  2013  0.846207  0.023065   98  4616516   632  2626       0.134247   \n",
       "13  2014  0.816596  0.022084   92  4631845   563  2806       0.140458   \n",
       "14  2015  0.831484  0.022584   90  4634783   301  2357       0.230179   \n",
       "15  2016  0.849591  0.035230  118  4644970   289  2541       0.289926   \n",
       "16  2017  0.874518  0.015564   53  4633152   360  2516       0.128329   \n",
       "17  2018  0.843105  0.017712   65  4631537   281  2693       0.187861   \n",
       "18  2019  0.840833  0.010959   35  4633859   324  1685       0.097493   \n",
       "19  2020  0.847943  0.011809   43  4631100   281  2116       0.132716   \n",
       "\n",
       "    Recall_0.5    F1_0.5  \n",
       "0     0.028020  0.041861  \n",
       "1     0.027503  0.044405  \n",
       "2     0.024270  0.041318  \n",
       "3     0.024498  0.041647  \n",
       "4     0.023627  0.042383  \n",
       "5     0.022262  0.040404  \n",
       "6     0.020897  0.038651  \n",
       "7     0.025392  0.044306  \n",
       "8     0.029719  0.047971  \n",
       "9     0.019377  0.031638  \n",
       "10    0.036683  0.059915  \n",
       "11    0.029165  0.043446  \n",
       "12    0.035977  0.056746  \n",
       "13    0.031746  0.051787  \n",
       "14    0.036780  0.063425  \n",
       "15    0.044378  0.076973  \n",
       "16    0.020631  0.035547  \n",
       "17    0.023568  0.041881  \n",
       "18    0.020349  0.033670  \n",
       "19    0.019917  0.034636  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del all variables to free up memory\n",
    "del mod_Human\n",
    "del results\n",
    "del results_pd\n",
    "# clean the cache\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all data\n",
    "for name in dir():\n",
    "    if not name.startswith('_'):\n",
    "        del globals()[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = \"Extended_Data_Water_Year_no_riparian_group_veg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing years: 100%|██████████| 20/20 [58:11<00:00, 174.56s/it] \n"
     ]
    }
   ],
   "source": [
    "# save all parquet to csv\n",
    "years = range(2001, 2021)\n",
    "\n",
    "input_path = f'../../Clean_Data/Model_Data/Evaluation/Features_w_Label_w_pred/{model_version}/parquet'\n",
    "output_path = f'../../Clean_Data/Model_Data/Evaluation/Features_w_Label_w_pred/{model_version}/csv'\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "for year in tqdm(years, desc=\"Processing years\"):\n",
    "    # read the parquet file\n",
    "    df = pd.read_parquet(f'{input_path}/{year}_predictions.parquet')  \n",
    "    # write to csv\n",
    "    df.to_csv(f'{output_path}/{year}_predictions.csv', index=False)\n",
    "\n",
    "    # clean up the dataframes\n",
    "    del df\n",
    "    # clean the cache\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
