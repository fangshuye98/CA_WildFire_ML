{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each weather data \n",
    "- save the raw data to parquet file\n",
    "- join w veg data to reduce # of grids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import pyproj\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas version\n",
      "2.2.2\n",
      "Geopandas version\n",
      "0.14.2\n",
      "Xarray version\n",
      "2023.6.0\n",
      "Pyproj version\n",
      "3.6.1\n"
     ]
    }
   ],
   "source": [
    "# check python version and all packages version\n",
    "def check_python_version():\n",
    "    import sys\n",
    "    print(\"Python version\")\n",
    "    print (sys.version)\n",
    "    print(\"Pandas version\")\n",
    "    print(pd.__version__)\n",
    "    print(\"Geopandas version\")\n",
    "    print(gpd.__version__)\n",
    "    print(\"Xarray version\")\n",
    "    print(xr.__version__)\n",
    "    print(\"Pyproj version\")\n",
    "    print(pyproj.__version__)\n",
    "\n",
    "check_python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dead_fuel_moisture_1000hr.2001.2023.CA.nc',\n",
       " 'dead_fuel_moisture_100hr.2001.2023.CA.nc',\n",
       " 'expanded_Palmer_Drought_Severity_Index.2001.2023.CA.nc',\n",
       " 'max_air_temperature.2001.2023.CA-008.nc',\n",
       " 'max_relative_humidity.2001.2023.CA.nc',\n",
       " 'max_wind_speed.2001.2023.CA.nc',\n",
       " 'min_air_temperature.2001.2023.CA-009.nc',\n",
       " 'min_relative_humidity.2001.2023.CA.nc',\n",
       " 'Palmer_Drought_Severity_Index.2001.2023.CA.nc',\n",
       " 'precipitation_amount.2001.2023.CA.nc',\n",
       " 'specific_humidity.2001.2023.CA.nc',\n",
       " 'surface_downwelling_shortwave_flux.2001.2023.CA.nc',\n",
       " 'wind_from_direction.2001.2023.CA.nc',\n",
       " 'wind_speed.2001.2023.CA.nc']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('../Weather_Data/')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../Weather_Data/'\n",
    "# Load the first dataset to use as a reference\n",
    "# reference_ds = xr.open_dataset(os.path.join(data_dir, files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: dead_fuel_moisture_1000hr.2001.2023.CA.nc\n",
      "Dimensions: Frozen({'day': 8400, 'lon': 259, 'lat': 240})\n",
      "Coordinates: Coordinates:\n",
      "  * day      (day) datetime64[ns] 2001-01-01 2001-01-02 ... 2023-12-31\n",
      "  * lon      (lon) float64 -124.8 -124.7 -124.7 -124.6 ... -114.1 -114.1 -114.0\n",
      "  * lat      (lat) float64 41.98 41.94 41.9 41.86 ... 32.15 32.11 32.07 32.03\n",
      "Data variables: Data variables:\n",
      "    dead_fuel_moisture_1000hr  (day, lat, lon) float32 ...\n",
      "\n",
      "File: dead_fuel_moisture_100hr.2001.2023.CA.nc\n",
      "Dimensions: Frozen({'day': 8400, 'lon': 259, 'lat': 240})\n",
      "Coordinates: Coordinates:\n",
      "  * day      (day) datetime64[ns] 2001-01-01 2001-01-02 ... 2023-12-31\n",
      "  * lon      (lon) float64 -124.8 -124.7 -124.7 -124.6 ... -114.1 -114.1 -114.0\n",
      "  * lat      (lat) float64 41.98 41.94 41.9 41.86 ... 32.15 32.11 32.07 32.03\n",
      "Data variables: Data variables:\n",
      "    dead_fuel_moisture_100hr  (day, lat, lon) float32 ...\n",
      "\n",
      "File: expanded_Palmer_Drought_Severity_Index.2001.2023.CA.nc\n",
      "Dimensions: Frozen({'day': 8400, 'lon': 259, 'lat': 240})\n",
      "Coordinates: Coordinates:\n",
      "  * day      (day) datetime64[ns] 2001-01-01 2001-01-02 ... 2023-12-31\n",
      "  * lon      (lon) float64 -124.8 -124.7 -124.7 -124.6 ... -114.1 -114.1 -114.0\n",
      "  * lat      (lat) float64 41.98 41.94 41.9 41.86 ... 32.15 32.11 32.07 32.03\n",
      "Data variables: Data variables:\n",
      "    pdsi      (day, lat, lon) float32 ...\n",
      "    category  (day, lat, lon) float32 ...\n",
      "\n",
      "File: max_air_temperature.2001.2023.CA-008.nc\n",
      "Dimensions: Frozen({'day': 8400, 'lon': 259, 'lat': 240})\n",
      "Coordinates: Coordinates:\n",
      "  * day      (day) datetime64[ns] 2001-01-01 2001-01-02 ... 2023-12-31\n",
      "  * lon      (lon) float64 -124.8 -124.7 -124.7 -124.6 ... -114.1 -114.1 -114.0\n",
      "  * lat      (lat) float64 41.98 41.94 41.9 41.86 ... 32.15 32.11 32.07 32.03\n",
      "Data variables: Data variables:\n",
      "    air_temperature  (day, lat, lon) float64 ...\n",
      "\n",
      "File: max_relative_humidity.2001.2023.CA.nc\n",
      "Dimensions: Frozen({'day': 8400, 'lon': 259, 'lat': 240})\n",
      "Coordinates: Coordinates:\n",
      "  * day      (day) datetime64[ns] 2001-01-01 2001-01-02 ... 2023-12-31\n",
      "  * lon      (lon) float64 -124.8 -124.7 -124.7 -124.6 ... -114.1 -114.1 -114.0\n",
      "  * lat      (lat) float64 41.98 41.94 41.9 41.86 ... 32.15 32.11 32.07 32.03\n",
      "Data variables: Data variables:\n",
      "    relative_humidity  (day, lat, lon) float32 ...\n",
      "\n",
      "File: max_wind_speed.2001.2023.CA.nc\n",
      "Dimensions: Frozen({'day': 8400, 'lon': 259, 'lat': 240})\n",
      "Coordinates: Coordinates:\n",
      "  * day      (day) datetime64[ns] 2001-01-01 2001-01-02 ... 2023-12-31\n",
      "  * lon      (lon) float64 -124.8 -124.7 -124.7 -124.6 ... -114.1 -114.1 -114.0\n",
      "  * lat      (lat) float64 41.98 41.94 41.9 41.86 ... 32.15 32.11 32.07 32.03\n",
      "Data variables: Data variables:\n",
      "    max_wind_speed  (day, lat, lon) float32 ...\n",
      "\n",
      "File: min_air_temperature.2001.2023.CA-009.nc\n",
      "Dimensions: Frozen({'day': 8400, 'lon': 259, 'lat': 240})\n",
      "Coordinates: Coordinates:\n",
      "  * day      (day) datetime64[ns] 2001-01-01 2001-01-02 ... 2023-12-31\n",
      "  * lon      (lon) float64 -124.8 -124.7 -124.7 -124.6 ... -114.1 -114.1 -114.0\n",
      "  * lat      (lat) float64 41.98 41.94 41.9 41.86 ... 32.15 32.11 32.07 32.03\n",
      "Data variables: Data variables:\n",
      "    air_temperature  (day, lat, lon) float64 ...\n",
      "\n",
      "File: min_relative_humidity.2001.2023.CA.nc\n",
      "Dimensions: Frozen({'day': 8400, 'lon': 259, 'lat': 240})\n",
      "Coordinates: Coordinates:\n",
      "  * day      (day) datetime64[ns] 2001-01-01 2001-01-02 ... 2023-12-31\n",
      "  * lon      (lon) float64 -124.8 -124.7 -124.7 -124.6 ... -114.1 -114.1 -114.0\n",
      "  * lat      (lat) float64 41.98 41.94 41.9 41.86 ... 32.15 32.11 32.07 32.03\n",
      "Data variables: Data variables:\n",
      "    relative_humidity  (day, lat, lon) float32 ...\n",
      "\n",
      "File: Palmer_Drought_Severity_Index.2001.2023.CA.nc\n",
      "Dimensions: Frozen({'day': 1679, 'lon': 259, 'lat': 240})\n",
      "Coordinates: Coordinates:\n",
      "  * day      (day) datetime64[ns] 2001-01-05 2001-01-10 ... 2023-12-31\n",
      "  * lon      (lon) float64 -124.8 -124.7 -124.7 -124.6 ... -114.1 -114.1 -114.0\n",
      "  * lat      (lat) float64 41.98 41.94 41.9 41.86 ... 32.15 32.11 32.07 32.03\n",
      "Data variables: Data variables:\n",
      "    pdsi      (day, lat, lon) float32 ...\n",
      "    category  (day, lat, lon) float32 ...\n",
      "\n",
      "File: precipitation_amount.2001.2023.CA.nc\n",
      "Dimensions: Frozen({'day': 8400, 'lon': 259, 'lat': 240})\n",
      "Coordinates: Coordinates:\n",
      "  * day      (day) datetime64[ns] 2001-01-01 2001-01-02 ... 2023-12-31\n",
      "  * lon      (lon) float64 -124.8 -124.7 -124.7 -124.6 ... -114.1 -114.1 -114.0\n",
      "  * lat      (lat) float64 41.98 41.94 41.9 41.86 ... 32.15 32.11 32.07 32.03\n",
      "Data variables: Data variables:\n",
      "    precipitation_amount  (day, lat, lon) float32 ...\n",
      "\n",
      "File: specific_humidity.2001.2023.CA.nc\n",
      "Dimensions: Frozen({'day': 8400, 'lon': 259, 'lat': 240})\n",
      "Coordinates: Coordinates:\n",
      "  * day      (day) datetime64[ns] 2001-01-01 2001-01-02 ... 2023-12-31\n",
      "  * lon      (lon) float64 -124.8 -124.7 -124.7 -124.6 ... -114.1 -114.1 -114.0\n",
      "  * lat      (lat) float64 41.98 41.94 41.9 41.86 ... 32.15 32.11 32.07 32.03\n",
      "Data variables: Data variables:\n",
      "    specific_humidity  (day, lat, lon) float32 ...\n",
      "\n",
      "File: surface_downwelling_shortwave_flux.2001.2023.CA.nc\n",
      "Dimensions: Frozen({'day': 8400, 'lon': 259, 'lat': 240})\n",
      "Coordinates: Coordinates:\n",
      "  * day      (day) datetime64[ns] 2001-01-01 2001-01-02 ... 2023-12-31\n",
      "  * lon      (lon) float64 -124.8 -124.7 -124.7 -124.6 ... -114.1 -114.1 -114.0\n",
      "  * lat      (lat) float64 41.98 41.94 41.9 41.86 ... 32.15 32.11 32.07 32.03\n",
      "Data variables: Data variables:\n",
      "    surface_downwelling_shortwave_flux_in_air  (day, lat, lon) float32 ...\n",
      "\n",
      "File: wind_from_direction.2001.2023.CA.nc\n",
      "Dimensions: Frozen({'day': 8400, 'lon': 259, 'lat': 240})\n",
      "Coordinates: Coordinates:\n",
      "  * day      (day) datetime64[ns] 2001-01-01 2001-01-02 ... 2023-12-31\n",
      "  * lon      (lon) float64 -124.8 -124.7 -124.7 -124.6 ... -114.1 -114.1 -114.0\n",
      "  * lat      (lat) float64 41.98 41.94 41.9 41.86 ... 32.15 32.11 32.07 32.03\n",
      "Data variables: Data variables:\n",
      "    wind_from_direction  (day, lat, lon) float32 ...\n",
      "\n",
      "File: wind_speed.2001.2023.CA.nc\n",
      "Dimensions: Frozen({'day': 8400, 'lon': 259, 'lat': 240})\n",
      "Coordinates: Coordinates:\n",
      "  * day      (day) datetime64[ns] 2001-01-01 2001-01-02 ... 2023-12-31\n",
      "  * lon      (lon) float64 -124.8 -124.7 -124.7 -124.6 ... -114.1 -114.1 -114.0\n",
      "  * lat      (lat) float64 41.98 41.94 41.9 41.86 ... 32.15 32.11 32.07 32.03\n",
      "Data variables: Data variables:\n",
      "    wind_speed  (day, lat, lon) float32 ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# go through all the files in ../Weather_Data/, print the dimensions and coordinates\n",
    "for file in files:\n",
    "    ds = xr.open_dataset(os.path.join(data_dir, file))\n",
    "    print(f\"File: {file}\")\n",
    "    print(f\"Dimensions: {ds.dims}\")\n",
    "    print(f\"Coordinates: {ds.coords}\")\n",
    "    print(f\"Data variables: {ds.data_vars}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming air_temperature to max_air_temperature\n",
      "Renaming relative_humidity to max_relative_humidity\n",
      "Renaming air_temperature to min_air_temperature\n",
      "Renaming relative_humidity to min_relative_humidity\n",
      "Dimensions or coordinates do not match for file: Palmer_Drought_Severity_Index.2001.2023.CA.nc\n"
     ]
    }
   ],
   "source": [
    "# Function to check if dimensions and coordinates match\n",
    "def check_compatibility(ds1, ds2):\n",
    "    return ds1.dims == ds2.dims and all(ds1.coords[dim].equals(ds2.coords[dim]) for dim in ds1.dims)\n",
    "\n",
    "# Initialize a list to store datasets and file names\n",
    "datasets = []\n",
    "compatible_files = []\n",
    "\n",
    "# Load the reference dataset\n",
    "reference_file = files[0]\n",
    "reference_ds = xr.open_dataset(os.path.join(data_dir, reference_file))\n",
    "datasets.append(reference_ds)\n",
    "compatible_files.append(reference_file)\n",
    "\n",
    "# Iterate over the remaining files and check compatibility\n",
    "for file in files[1:]:\n",
    "    file_name = file.split('.')[0]\n",
    "    ds = xr.open_dataset(os.path.join(data_dir, file))\n",
    "    # if file_name contains temperature, rename the variable to file_names\n",
    "    if 'temperature' in file or 'relative_humidity' in file:\n",
    "        # get the name of data variable\n",
    "        current_data_var_name = list(ds.data_vars)[0]\n",
    "        # rename the data variable\n",
    "        ds = ds.rename({current_data_var_name: file_name})\n",
    "        # print the replacement action\n",
    "        print(f\"Renaming {current_data_var_name} to {file_name}\")\n",
    "    if check_compatibility(reference_ds, ds):\n",
    "        datasets.append(ds)\n",
    "        compatible_files.append(file)\n",
    "    else:\n",
    "        print(f\"Dimensions or coordinates do not match for file: {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dead_fuel_moisture_1000hr.2001.2023.CA.nc',\n",
       " 'dead_fuel_moisture_100hr.2001.2023.CA.nc',\n",
       " 'expanded_Palmer_Drought_Severity_Index.2001.2023.CA.nc',\n",
       " 'max_air_temperature.2001.2023.CA-008.nc',\n",
       " 'max_relative_humidity.2001.2023.CA.nc',\n",
       " 'max_wind_speed.2001.2023.CA.nc',\n",
       " 'min_air_temperature.2001.2023.CA-009.nc',\n",
       " 'min_relative_humidity.2001.2023.CA.nc',\n",
       " 'precipitation_amount.2001.2023.CA.nc',\n",
       " 'specific_humidity.2001.2023.CA.nc',\n",
       " 'surface_downwelling_shortwave_flux.2001.2023.CA.nc',\n",
       " 'wind_from_direction.2001.2023.CA.nc',\n",
       " 'wind_speed.2001.2023.CA.nc']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compatible_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dead_fuel_moisture_1000hr.2001.2023.CA.nc as ../Clean_Data/Weather_Data/dead_fuel_moisture_1000hr.parquet\n",
      "Saved dead_fuel_moisture_100hr.2001.2023.CA.nc as ../Clean_Data/Weather_Data/dead_fuel_moisture_100hr.parquet\n",
      "Saved expanded_Palmer_Drought_Severity_Index.2001.2023.CA.nc as ../Clean_Data/Weather_Data/expanded_Palmer_Drought_Severity_Index.parquet\n",
      "Saved max_air_temperature.2001.2023.CA-008.nc as ../Clean_Data/Weather_Data/max_air_temperature.parquet\n",
      "Saved max_relative_humidity.2001.2023.CA.nc as ../Clean_Data/Weather_Data/max_relative_humidity.parquet\n",
      "Saved max_wind_speed.2001.2023.CA.nc as ../Clean_Data/Weather_Data/max_wind_speed.parquet\n",
      "Saved min_air_temperature.2001.2023.CA-009.nc as ../Clean_Data/Weather_Data/min_air_temperature.parquet\n",
      "Saved min_relative_humidity.2001.2023.CA.nc as ../Clean_Data/Weather_Data/min_relative_humidity.parquet\n",
      "Saved precipitation_amount.2001.2023.CA.nc as ../Clean_Data/Weather_Data/precipitation_amount.parquet\n",
      "Saved specific_humidity.2001.2023.CA.nc as ../Clean_Data/Weather_Data/specific_humidity.parquet\n",
      "Saved surface_downwelling_shortwave_flux.2001.2023.CA.nc as ../Clean_Data/Weather_Data/surface_downwelling_shortwave_flux.parquet\n",
      "Saved wind_from_direction.2001.2023.CA.nc as ../Clean_Data/Weather_Data/wind_from_direction.parquet\n",
      "Saved wind_speed.2001.2023.CA.nc as ../Clean_Data/Weather_Data/wind_speed.parquet\n"
     ]
    }
   ],
   "source": [
    "# Perform actions for each compatible file\n",
    "for file in compatible_files:\n",
    "    ds = xr.open_dataset(os.path.join(data_dir, file))\n",
    "    \n",
    "    # Convert the dataset to a pandas DataFrame\n",
    "    panda_df = ds.to_dataframe().reset_index()\n",
    "    \n",
    "    # Save the DataFrame as a Parquet file\n",
    "    output_file = f'../Clean_Data/Weather_Data/{file.split(\".\")[0]}.parquet'\n",
    "    panda_df.to_parquet(output_file)\n",
    "    \n",
    "    # Print the action\n",
    "    print(f\"Saved {file} as {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all datasets\n",
    "# merged_weather_dat = xr.merge(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:                                    (day: 8400, lon: 259, lat: 240)\n",
      "Coordinates:\n",
      "  * day                                        (day) datetime64[ns] 2001-01-0...\n",
      "  * lon                                        (lon) float64 -124.8 ... -114.0\n",
      "  * lat                                        (lat) float64 41.98 ... 32.03\n",
      "Data variables: (12/14)\n",
      "    dead_fuel_moisture_1000hr                  (day, lat, lon) float32 ...\n",
      "    dead_fuel_moisture_100hr                   (day, lat, lon) float32 ...\n",
      "    pdsi                                       (day, lat, lon) float32 ...\n",
      "    category                                   (day, lat, lon) float32 ...\n",
      "    max_air_temperature                        (day, lat, lon) float64 ...\n",
      "    max_relative_humidity                      (day, lat, lon) float32 ...\n",
      "    ...                                         ...\n",
      "    min_relative_humidity                      (day, lat, lon) float32 ...\n",
      "    precipitation_amount                       (day, lat, lon) float32 ...\n",
      "    specific_humidity                          (day, lat, lon) float32 ...\n",
      "    surface_downwelling_shortwave_flux_in_air  (day, lat, lon) float32 ...\n",
      "    wind_from_direction                        (day, lat, lon) float32 ...\n",
      "    wind_speed                                 (day, lat, lon) float32 ...\n",
      "Attributes: (12/22)\n",
      "    CDI:                        Climate Data Interface version 2.1.1 (https:/...\n",
      "    Conventions:                CF-1.6\n",
      "    geospatial_bounds_crs:      EPSG:4326\n",
      "    geospatial_bounds:          POLYGON((-124.7666666333333 49.40000000000000...\n",
      "    geospatial_lat_min:         25.066666666666666\n",
      "    geospatial_lat_max:         49.40000000000000\n",
      "    ...                         ...\n",
      "    note2:                      Citation: Abatzoglou, J.T., 2013, Development...\n",
      "    note3:                      Data in slices after last_permanent_slice (1-...\n",
      "    note4:                      Data in slices after last_provisional_slice (...\n",
      "    note5:                      Days correspond approximately to calendar day...\n",
      "    history:                    Fri Nov 29 19:49:53 2024: cdo setmissval,nan ...\n",
      "    CDO:                        Climate Data Operators version 2.1.1 (https:/...\n"
     ]
    }
   ],
   "source": [
    "# Print the dataset summary\n",
    "# print(merged_weather_dat)\n",
    "\n",
    "# Print the coordinates\n",
    "# print(merged_weather_dat.coords)\n",
    "\n",
    "# Print the data variables\n",
    "# print(merged_weather_dat.data_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 23.3 GiB for an array with shape (12, 522144000) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# save the merged weather data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m panda_df \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_weather_dat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[1;32mc:\\Users\\fangshuye\\AppData\\Local\\anaconda3\\envs\\py311\\Lib\\site-packages\\xarray\\core\\dataset.py:6289\u001b[0m, in \u001b[0;36mDataset.to_dataframe\u001b[1;34m(self, dim_order)\u001b[0m\n\u001b[0;32m   6261\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert this dataset into a pandas.DataFrame.\u001b[39;00m\n\u001b[0;32m   6262\u001b[0m \n\u001b[0;32m   6263\u001b[0m \u001b[38;5;124;03mNon-index variables in this dataset form the columns of the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6284\u001b[0m \n\u001b[0;32m   6285\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6287\u001b[0m ordered_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_dim_order(dim_order\u001b[38;5;241m=\u001b[39mdim_order)\n\u001b[1;32m-> 6289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mordered_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mordered_dims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fangshuye\\AppData\\Local\\anaconda3\\envs\\py311\\Lib\\site-packages\\xarray\\core\\dataset.py:6258\u001b[0m, in \u001b[0;36mDataset._to_dataframe\u001b[1;34m(self, ordered_dims)\u001b[0m\n\u001b[0;32m   6253\u001b[0m data \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6254\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables[k]\u001b[38;5;241m.\u001b[39mset_dims(ordered_dims)\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   6255\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m columns\n\u001b[0;32m   6256\u001b[0m ]\n\u001b[0;32m   6257\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoords\u001b[38;5;241m.\u001b[39mto_index([\u001b[38;5;241m*\u001b[39mordered_dims])\n\u001b[1;32m-> 6258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fangshuye\\AppData\\Local\\anaconda3\\envs\\py311\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\fangshuye\\AppData\\Local\\anaconda3\\envs\\py311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fangshuye\\AppData\\Local\\anaconda3\\envs\\py311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    149\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_block_manager_from_column_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32mc:\\Users\\fangshuye\\AppData\\Local\\anaconda3\\envs\\py311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2144\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2142\u001b[0m     raise_construction_error(\u001b[38;5;28mlen\u001b[39m(arrays), arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, axes, e)\n\u001b[0;32m   2143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consolidate:\n\u001b[1;32m-> 2144\u001b[0m     \u001b[43mmgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mgr\n",
      "File \u001b[1;32mc:\\Users\\fangshuye\\AppData\\Local\\anaconda3\\envs\\py311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1788\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1783\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[0;32m   1785\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1788\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m \u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1789\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fangshuye\\AppData\\Local\\anaconda3\\envs\\py311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2269\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2267\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2269\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2270\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[0;32m   2271\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2272\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32mc:\\Users\\fangshuye\\AppData\\Local\\anaconda3\\envs\\py311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2294\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2287\u001b[0m new_values: ArrayLike\n\u001b[0;32m   2289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(blocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   2290\u001b[0m     \u001b[38;5;66;03m# error: List comprehension has incompatible type List[Union[ndarray,\u001b[39;00m\n\u001b[0;32m   2291\u001b[0m     \u001b[38;5;66;03m# ExtensionArray]]; expected List[Union[complex, generic,\u001b[39;00m\n\u001b[0;32m   2292\u001b[0m     \u001b[38;5;66;03m# Sequence[Union[int, float, complex, str, bytes, generic]],\u001b[39;00m\n\u001b[0;32m   2293\u001b[0m     \u001b[38;5;66;03m# Sequence[Sequence[Any]], SupportsArray]]\u001b[39;00m\n\u001b[1;32m-> 2294\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   2295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2296\u001b[0m     bvals \u001b[38;5;241m=\u001b[39m [blk\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m blocks]\n",
      "File \u001b[1;32mc:\\Users\\fangshuye\\AppData\\Local\\anaconda3\\envs\\py311\\Lib\\site-packages\\numpy\\core\\shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    288\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 23.3 GiB for an array with shape (12, 522144000) and data type float32"
     ]
    }
   ],
   "source": [
    "# save the merged weather data\n",
    "# panda_df = merged_weather_dat.to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the parquet file\n",
    "# panda_df = pd.read_parquet('../Clean_Data/merged_weather_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda_df = panda_df.dropna(how='all', subset=merged_weather_dat.data_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(519859200, 14)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panda_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dead_fuel_moisture_1000hr',\n",
       " 'dead_fuel_moisture_100hr',\n",
       " 'max_relative_humidity',\n",
       " 'min_relative_humidity',\n",
       " 'precipitation_amount',\n",
       " 'specific_humidity',\n",
       " 'surface_downwelling_shortwave_flux_in_air',\n",
       " 'wind_from_direction',\n",
       " 'wind_speed']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove N/A rows, this time still check merged_weather_dat.data_vars except for max_air_temperature, min_air_temperature\n",
    "cols_wo_air_temperature = [col for col in merged_weather_dat.data_vars if col not in ['max_air_temperature', 'min_air_temperature']]\n",
    "cols_wo_air_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where all values in cols_wo_air_temperature are NaN\n",
    "panda_df = panda_df.dropna(how='all', subset=cols_wo_air_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207328800, 14)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panda_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda_df.to_parquet('../Clean_Data/merged_weather_data_complete.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda_df = pd.read_parquet('../Clean_Data/merged_weather_data_complete.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207328800, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panda_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_lat_pair_weather_match_veg = pd.read_parquet('../Clean_Data/lon_lat_pair_weather_match_veg.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17703, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lon_lat_pair_weather_match_veg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>type</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>-124.391667</td>\n",
       "      <td>40.441667</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.826642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>-124.391667</td>\n",
       "      <td>40.400000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.827314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>40.566667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.824622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>40.525000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.825296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>40.483333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.825969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lon        lat  type  distance\n",
       "2197 -124.391667  40.441667   7.0  1.826642\n",
       "2198 -124.391667  40.400000  25.0  1.827314\n",
       "2434 -124.350000  40.566667   1.0  1.824622\n",
       "2435 -124.350000  40.525000   8.0  1.825296\n",
       "2436 -124.350000  40.483333  25.0  1.825969"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lon_lat_pair_weather_match_veg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm if lon and lat are unique in lon_lat_pair_weather_match_veg\n",
    "lon_lat_pair_weather_match_veg[['lon', 'lat']].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['max_wind_speed.2001.2023.CA.nc',\n",
       " 'min_air_temperature.2001.2023.CA-009.nc',\n",
       " 'min_relative_humidity.2001.2023.CA.nc',\n",
       " 'precipitation_amount.2001.2023.CA.nc',\n",
       " 'specific_humidity.2001.2023.CA.nc',\n",
       " 'surface_downwelling_shortwave_flux.2001.2023.CA.nc',\n",
       " 'wind_from_direction.2001.2023.CA.nc',\n",
       " 'wind_speed.2001.2023.CA.nc']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compatible_files[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dead_fuel_moisture_1000hr.2001.2023.CA.nc\n",
      "(522144000, 4) (148705200, 4)\n",
      "==================================================\n",
      "dead_fuel_moisture_100hr.2001.2023.CA.nc\n",
      "(522144000, 4) (148705200, 4)\n",
      "==================================================\n",
      "expanded_Palmer_Drought_Severity_Index.2001.2023.CA.nc\n",
      "(522144000, 5) (148705200, 5)\n",
      "==================================================\n",
      "max_air_temperature.2001.2023.CA-008.nc\n",
      "(522144000, 4) (148705200, 4)\n",
      "==================================================\n",
      "max_relative_humidity.2001.2023.CA.nc\n",
      "(522144000, 4) (148705200, 4)\n",
      "==================================================\n",
      "max_wind_speed.2001.2023.CA.nc\n",
      "(522144000, 4) (148705200, 4)\n",
      "==================================================\n",
      "min_air_temperature.2001.2023.CA-009.nc\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.11 GiB for an array with shape (148705200,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m panda_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Clean_Data/Weather_Data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# merge the dataframes\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m panda_df_filtered \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlon_lat_pair_weather_match_veg\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpanda_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minner\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# save the merged dataframe\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Save the DataFrame as a Parquet file\u001b[39;00m\n\u001b[0;32m     10\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Clean_Data/Weather_Data_w_Veg_Filter/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_filtered.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\fangshuye\\AppData\\Local\\anaconda3\\envs\\py311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    171\u001b[0m         left_df,\n\u001b[0;32m    172\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fangshuye\\AppData\\Local\\anaconda3\\envs\\py311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:886\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m--> 886\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    888\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_and_concat(\n\u001b[0;32m    889\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    890\u001b[0m )\n\u001b[0;32m    891\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n",
      "File \u001b[1;32mc:\\Users\\fangshuye\\AppData\\Local\\anaconda3\\envs\\py311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1151\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     join_index, right_indexer, left_indexer \u001b[38;5;241m=\u001b[39m _left_join_on_index(\n\u001b[0;32m   1148\u001b[0m         right_ax, left_ax, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1151\u001b[0m     (left_indexer, right_indexer) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_index:\n\u001b[0;32m   1154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\fangshuye\\AppData\\Local\\anaconda3\\envs\\py311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1125\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_indexers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# make mypy happy\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masof\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_join_indexers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhow\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fangshuye\\AppData\\Local\\anaconda3\\envs\\py311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1759\u001b[0m, in \u001b[0;36mget_join_indexers\u001b[1;34m(left_keys, right_keys, sort, how)\u001b[0m\n\u001b[0;32m   1757\u001b[0m     _, lidx, ridx \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39mjoin(right, how\u001b[38;5;241m=\u001b[39mhow, return_indexers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1759\u001b[0m     lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[43mget_join_indexers_non_unique\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\n\u001b[0;32m   1761\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lidx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_range_indexer(lidx, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[0;32m   1764\u001b[0m     lidx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fangshuye\\AppData\\Local\\anaconda3\\envs\\py311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1799\u001b[0m, in \u001b[0;36mget_join_indexers_non_unique\u001b[1;34m(left, right, sort, how)\u001b[0m\n\u001b[0;32m   1797\u001b[0m     ridx, lidx \u001b[38;5;241m=\u001b[39m libjoin\u001b[38;5;241m.\u001b[39mleft_outer_join(rkey, lkey, count, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[0;32m   1798\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1799\u001b[0m     lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[43mlibjoin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_join\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1800\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1801\u001b[0m     lidx, ridx \u001b[38;5;241m=\u001b[39m libjoin\u001b[38;5;241m.\u001b[39mfull_outer_join(lkey, rkey, count)\n",
      "File \u001b[1;32mjoin.pyx:83\u001b[0m, in \u001b[0;36mpandas._libs.join.inner_join\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.11 GiB for an array with shape (148705200,) and data type int64"
     ]
    }
   ],
   "source": [
    "# read each saved parquet file\n",
    "for file in compatible_files:\n",
    "    # print the file name\n",
    "    print(file)\n",
    "    panda_df = pd.read_parquet(f'../Clean_Data/Weather_Data/{file.split(\".\")[0]}.parquet')\n",
    "    # merge the dataframes\n",
    "    panda_df_filtered = pd.merge(lon_lat_pair_weather_match_veg[['lon', 'lat']], panda_df, on=['lon', 'lat'], how='inner')\n",
    "    # save the merged dataframe\n",
    "    # Save the DataFrame as a Parquet file\n",
    "    output_file = f'../Clean_Data/Weather_Data_w_Veg_Filter/{file.split(\".\")[0]}_filtered.parquet'\n",
    "    panda_df_filtered.to_parquet(output_file)\n",
    "    # show # of rows before and after merging\n",
    "    print(panda_df.shape, panda_df_filtered.shape)\n",
    "    # print separator\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_wind_speed.2001.2023.CA.nc\n",
      "(522144000, 4) (148705200, 4)\n",
      "==================================================\n",
      "min_air_temperature.2001.2023.CA-009.nc\n",
      "(522144000, 4) (148705200, 4)\n",
      "==================================================\n",
      "min_relative_humidity.2001.2023.CA.nc\n",
      "(522144000, 4) (148705200, 4)\n",
      "==================================================\n",
      "precipitation_amount.2001.2023.CA.nc\n",
      "(522144000, 4) (148705200, 4)\n",
      "==================================================\n",
      "specific_humidity.2001.2023.CA.nc\n",
      "(522144000, 4) (148705200, 4)\n",
      "==================================================\n",
      "surface_downwelling_shortwave_flux.2001.2023.CA.nc\n",
      "(522144000, 4) (148705200, 4)\n",
      "==================================================\n",
      "wind_from_direction.2001.2023.CA.nc\n",
      "(522144000, 4) (148705200, 4)\n",
      "==================================================\n",
      "wind_speed.2001.2023.CA.nc\n",
      "(522144000, 4) (148705200, 4)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# read each saved parquet file\n",
    "for file in compatible_files[5:]:\n",
    "    # print the file name\n",
    "    print(file)\n",
    "    panda_df = pd.read_parquet(f'../Clean_Data/Weather_Data/{file.split(\".\")[0]}.parquet')\n",
    "    # merge the dataframes\n",
    "    panda_df_filtered = pd.merge(lon_lat_pair_weather_match_veg[['lon', 'lat']], panda_df, on=['lon', 'lat'], how='inner')\n",
    "    # save the merged dataframe\n",
    "    # Save the DataFrame as a Parquet file\n",
    "    output_file = f'../Clean_Data/Weather_Data_w_Veg_Filter/{file.split(\".\")[0]}_filtered.parquet'\n",
    "    panda_df_filtered.to_parquet(output_file)\n",
    "    # show # of rows before and after merging\n",
    "    print(panda_df.shape, panda_df_filtered.shape)\n",
    "    # print separator\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146193600, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in panda_df, drop rows where lon and lat are not in lon_lat_pair_weather_match_veg using merge\n",
    "# weather_dat = panda_df.merge(lon_lat_pair_weather_match_veg[['lon', 'lat','type']], on=['lon', 'lat'], how='inner')\n",
    "# weather_dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_dat.to_parquet('../Clean_Data/merged_weather_data_w_veg.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old code, only save limited locations where fire event happened\n",
    "# panda_df.to_parquet('../Clean_Data/merged_weather_data_limited_locations.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
